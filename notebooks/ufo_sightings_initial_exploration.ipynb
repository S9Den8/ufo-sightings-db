{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d105a05b",
   "metadata": {},
   "source": [
    "# Unidentified Flying Object (UFO) Sightings - Initial Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e646d7",
   "metadata": {},
   "source": [
    "This notebook explores a dataset of 80,000+ reported UFO sightings around the world between November 11, 1906, and August 08, 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd16aa09",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "f19d4576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d3d36e",
   "metadata": {},
   "source": [
    "## 2. Load the Raw UFO Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "2f5d3880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nlnz8\\AppData\\Local\\Temp\\ipykernel_124244\\1935580793.py:1: DtypeWarning: Columns (5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"../data/ufo_sightings_raw.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/ufo_sightings_raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a730ba8",
   "metadata": {},
   "source": [
    "## 3. Inspect & Understand the Dataset Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18327bd5",
   "metadata": {},
   "source": [
    "### 3.1 Preview the Raw Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "b0d49f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-10-10 20:30:00</td>\n",
       "      <td>san marcos</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>2700</td>\n",
       "      <td>45 minutes</td>\n",
       "      <td>This event took place in early fall around 194...</td>\n",
       "      <td>2004-04-27</td>\n",
       "      <td>29.8830556</td>\n",
       "      <td>-97.941111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-10-10 21:00:00</td>\n",
       "      <td>lackland afb</td>\n",
       "      <td>tx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>light</td>\n",
       "      <td>7200</td>\n",
       "      <td>1-2 hrs</td>\n",
       "      <td>1949 Lackland AFB&amp;#44 TX.  Lights racing acros...</td>\n",
       "      <td>2005-12-16</td>\n",
       "      <td>29.38421</td>\n",
       "      <td>-98.581082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1955-10-10 17:00:00</td>\n",
       "      <td>chester (uk/england)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>20 seconds</td>\n",
       "      <td>Green/Orange circular disc over Chester&amp;#44 En...</td>\n",
       "      <td>2008-01-21</td>\n",
       "      <td>53.2</td>\n",
       "      <td>-2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956-10-10 21:00:00</td>\n",
       "      <td>edna</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>1/2 hour</td>\n",
       "      <td>My older brother and twin sister were leaving ...</td>\n",
       "      <td>2004-01-17</td>\n",
       "      <td>28.9783333</td>\n",
       "      <td>-96.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960-10-10 20:00:00</td>\n",
       "      <td>kaneohe</td>\n",
       "      <td>hi</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>900</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>AS a Marine 1st Lt. flying an FJ4B fighter/att...</td>\n",
       "      <td>2004-01-22</td>\n",
       "      <td>21.4180556</td>\n",
       "      <td>-157.803611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1961-10-10 19:00:00</td>\n",
       "      <td>bristol</td>\n",
       "      <td>tn</td>\n",
       "      <td>us</td>\n",
       "      <td>sphere</td>\n",
       "      <td>300</td>\n",
       "      <td>5 minutes</td>\n",
       "      <td>My father is now 89 my brother 52 the girl wit...</td>\n",
       "      <td>2007-04-27</td>\n",
       "      <td>36.595</td>\n",
       "      <td>-82.188889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1965-10-10 21:00:00</td>\n",
       "      <td>penarth (uk/wales)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "      <td>circle</td>\n",
       "      <td>180</td>\n",
       "      <td>about 3 mins</td>\n",
       "      <td>penarth uk  circle  3mins  stayed 30ft above m...</td>\n",
       "      <td>2006-02-14</td>\n",
       "      <td>51.434722</td>\n",
       "      <td>-3.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1965-10-10 23:45:00</td>\n",
       "      <td>norwalk</td>\n",
       "      <td>ct</td>\n",
       "      <td>us</td>\n",
       "      <td>disk</td>\n",
       "      <td>1200</td>\n",
       "      <td>20 minutes</td>\n",
       "      <td>A bright orange color changing to reddish colo...</td>\n",
       "      <td>1999-10-02</td>\n",
       "      <td>41.1175</td>\n",
       "      <td>-73.408333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1966-10-10 20:00:00</td>\n",
       "      <td>pell city</td>\n",
       "      <td>al</td>\n",
       "      <td>us</td>\n",
       "      <td>disk</td>\n",
       "      <td>180</td>\n",
       "      <td>3  minutes</td>\n",
       "      <td>Strobe Lighted disk shape object observed clos...</td>\n",
       "      <td>2009-03-19</td>\n",
       "      <td>33.5861111</td>\n",
       "      <td>-86.286111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1966-10-10 21:00:00</td>\n",
       "      <td>live oak</td>\n",
       "      <td>fl</td>\n",
       "      <td>us</td>\n",
       "      <td>disk</td>\n",
       "      <td>120</td>\n",
       "      <td>several minutes</td>\n",
       "      <td>Saucer zaps energy from powerline as my pregna...</td>\n",
       "      <td>2005-05-11</td>\n",
       "      <td>30.2947222</td>\n",
       "      <td>-82.984167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime                  city state country     shape  \\\n",
       "0  1949-10-10 20:30:00            san marcos    tx      us  cylinder   \n",
       "1  1949-10-10 21:00:00          lackland afb    tx     NaN     light   \n",
       "2  1955-10-10 17:00:00  chester (uk/england)   NaN      gb    circle   \n",
       "3  1956-10-10 21:00:00                  edna    tx      us    circle   \n",
       "4  1960-10-10 20:00:00               kaneohe    hi      us     light   \n",
       "5  1961-10-10 19:00:00               bristol    tn      us    sphere   \n",
       "6  1965-10-10 21:00:00    penarth (uk/wales)   NaN      gb    circle   \n",
       "7  1965-10-10 23:45:00               norwalk    ct      us      disk   \n",
       "8  1966-10-10 20:00:00             pell city    al      us      disk   \n",
       "9  1966-10-10 21:00:00              live oak    fl      us      disk   \n",
       "\n",
       "  duration (seconds) duration (hours/min)  \\\n",
       "0               2700           45 minutes   \n",
       "1               7200              1-2 hrs   \n",
       "2                 20           20 seconds   \n",
       "3                 20             1/2 hour   \n",
       "4                900           15 minutes   \n",
       "5                300            5 minutes   \n",
       "6                180         about 3 mins   \n",
       "7               1200           20 minutes   \n",
       "8                180           3  minutes   \n",
       "9                120      several minutes   \n",
       "\n",
       "                                            comments date posted    latitude  \\\n",
       "0  This event took place in early fall around 194...  2004-04-27  29.8830556   \n",
       "1  1949 Lackland AFB&#44 TX.  Lights racing acros...  2005-12-16    29.38421   \n",
       "2  Green/Orange circular disc over Chester&#44 En...  2008-01-21        53.2   \n",
       "3  My older brother and twin sister were leaving ...  2004-01-17  28.9783333   \n",
       "4  AS a Marine 1st Lt. flying an FJ4B fighter/att...  2004-01-22  21.4180556   \n",
       "5  My father is now 89 my brother 52 the girl wit...  2007-04-27      36.595   \n",
       "6  penarth uk  circle  3mins  stayed 30ft above m...  2006-02-14   51.434722   \n",
       "7  A bright orange color changing to reddish colo...  1999-10-02     41.1175   \n",
       "8  Strobe Lighted disk shape object observed clos...  2009-03-19  33.5861111   \n",
       "9  Saucer zaps energy from powerline as my pregna...  2005-05-11  30.2947222   \n",
       "\n",
       "   longitude   \n",
       "0  -97.941111  \n",
       "1  -98.581082  \n",
       "2   -2.916667  \n",
       "3  -96.645833  \n",
       "4 -157.803611  \n",
       "5  -82.188889  \n",
       "6   -3.180000  \n",
       "7  -73.408333  \n",
       "8  -86.286111  \n",
       "9  -82.984167  "
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d3f93f",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- Some values (e.g., NaN) in \"state\" and/or \"country\" are present.\n",
    "- Text fields appear inconsistent in formatting (e.g., varied capitalization, mixed formatting, and spacing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea07e98c",
   "metadata": {},
   "source": [
    "### 3.2 Inspect Column Types and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "ed56b1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80332 entries, 0 to 80331\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   datetime              80332 non-null  object \n",
      " 1   city                  80332 non-null  object \n",
      " 2   state                 74535 non-null  object \n",
      " 3   country               70662 non-null  object \n",
      " 4   shape                 78400 non-null  object \n",
      " 5   duration (seconds)    80332 non-null  object \n",
      " 6   duration (hours/min)  80332 non-null  object \n",
      " 7   comments              80317 non-null  object \n",
      " 8   date posted           80332 non-null  object \n",
      " 9   latitude              80332 non-null  object \n",
      " 10  longitude             80332 non-null  float64\n",
      "dtypes: float64(1), object(10)\n",
      "memory usage: 6.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada3caee",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- Several columns that should contain datetime or numeric values (e.g., \"latitude\", \"duration\" (seconds), \"datetime\", \"date posted\") were initially loaded as \"object\". \n",
    "- Erroneous dtypes prevent time-series, numeric, and geospatial analysis. \n",
    "- Several missing values present in multiple columns, especially \"country\", \"state\", and \"comments\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ae072",
   "metadata": {},
   "source": [
    "### 3.3 Summary Statistics for All Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "3694e021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>80332</td>\n",
       "      <td>80332</td>\n",
       "      <td>74535</td>\n",
       "      <td>70662</td>\n",
       "      <td>78400</td>\n",
       "      <td>80332</td>\n",
       "      <td>80332</td>\n",
       "      <td>80317</td>\n",
       "      <td>80332</td>\n",
       "      <td>80332</td>\n",
       "      <td>80332.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>69474</td>\n",
       "      <td>19900</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>705</td>\n",
       "      <td>8304</td>\n",
       "      <td>79997</td>\n",
       "      <td>317</td>\n",
       "      <td>23292</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2010-07-04 22:00:00</td>\n",
       "      <td>seattle</td>\n",
       "      <td>ca</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>300</td>\n",
       "      <td>5 minutes</td>\n",
       "      <td>Fireball</td>\n",
       "      <td>2009-12-12</td>\n",
       "      <td>47.6063889</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>36</td>\n",
       "      <td>525</td>\n",
       "      <td>9655</td>\n",
       "      <td>65114</td>\n",
       "      <td>16565</td>\n",
       "      <td>7070</td>\n",
       "      <td>4716</td>\n",
       "      <td>11</td>\n",
       "      <td>1510</td>\n",
       "      <td>481</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-86.772885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.697205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-176.658056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-112.073333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-87.903611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-78.755000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178.441900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime     city  state country  shape duration (seconds)  \\\n",
       "count                 80332    80332  74535   70662  78400              80332   \n",
       "unique                69474    19900     67       5     29                705   \n",
       "top     2010-07-04 22:00:00  seattle     ca      us  light                300   \n",
       "freq                     36      525   9655   65114  16565               7070   \n",
       "mean                    NaN      NaN    NaN     NaN    NaN                NaN   \n",
       "std                     NaN      NaN    NaN     NaN    NaN                NaN   \n",
       "min                     NaN      NaN    NaN     NaN    NaN                NaN   \n",
       "25%                     NaN      NaN    NaN     NaN    NaN                NaN   \n",
       "50%                     NaN      NaN    NaN     NaN    NaN                NaN   \n",
       "75%                     NaN      NaN    NaN     NaN    NaN                NaN   \n",
       "max                     NaN      NaN    NaN     NaN    NaN                NaN   \n",
       "\n",
       "       duration (hours/min)  comments date posted    latitude    longitude   \n",
       "count                 80332     80317       80332       80332  80332.000000  \n",
       "unique                 8304     79997         317       23292           NaN  \n",
       "top               5 minutes  Fireball  2009-12-12  47.6063889           NaN  \n",
       "freq                   4716        11        1510         481           NaN  \n",
       "mean                    NaN       NaN         NaN         NaN    -86.772885  \n",
       "std                     NaN       NaN         NaN         NaN     39.697205  \n",
       "min                     NaN       NaN         NaN         NaN   -176.658056  \n",
       "25%                     NaN       NaN         NaN         NaN   -112.073333  \n",
       "50%                     NaN       NaN         NaN         NaN    -87.903611  \n",
       "75%                     NaN       NaN         NaN         NaN    -78.755000  \n",
       "max                     NaN       NaN         NaN         NaN    178.441900  "
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66ee17b",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- High cardinality in text-based columns (e.g., 19,900 unique cities). *High cardinality = harder to group/visualize, harder to encode, slower/more expensive ops.*\n",
    "- Many stat fields are NaN because the corresponding columns are stored as objects instead of numeric/datetime.\n",
    "- Most common city (\"seattle\"), country (\"us\"), and shape (\"light\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91ca852",
   "metadata": {},
   "source": [
    "### 3.4 Dataset Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ce77e95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80332, 11)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e5d43f",
   "metadata": {},
   "source": [
    "**Notes**: \n",
    "The dataset contains 11 columns, and 80,332 reported UFO sightings, capturing time, location, duration, and descriptive comments. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddab363",
   "metadata": {},
   "source": [
    "### 3.5 Explore Key Categorical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338455db",
   "metadata": {},
   "source": [
    "#### 3.5.1 UFO Shapes Reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "afcfcc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape\n",
       "light        16565\n",
       "triangle      7865\n",
       "circle        7608\n",
       "fireball      6208\n",
       "other         5649\n",
       "unknown       5584\n",
       "sphere        5387\n",
       "disk          5213\n",
       "oval          3733\n",
       "formation     2457\n",
       "cigar         2057\n",
       "changing      1962\n",
       "flash         1328\n",
       "rectangle     1297\n",
       "cylinder      1283\n",
       "diamond       1178\n",
       "chevron        952\n",
       "egg            759\n",
       "teardrop       750\n",
       "cone           316\n",
       "cross          233\n",
       "delta            7\n",
       "round            2\n",
       "crescent         2\n",
       "pyramid          1\n",
       "flare            1\n",
       "hexagon          1\n",
       "dome             1\n",
       "changed          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"shape\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4cf6e9",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- It appears that the three most sighted shapes between 1906 and 2014 were \"light\", \"triangle\", and \"circle\". \n",
    "- The \"changed\" column is vague. Does \"changed\" indicate the witness saw the object change shape, or is it a data entry artifact? This may require further investigation. \n",
    "- The \"other\" category is quite significant (5649). The significant number of reports in the \"other\" category suggests ambiguous or inconsistent reporting. What types of descriptions fall into this label? Could this category be refined? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448425a8",
   "metadata": {},
   "source": [
    "#### 3.5.2 Country with the Most Sightings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5bcae37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "us    65114\n",
       "ca     3000\n",
       "gb     1905\n",
       "au      538\n",
       "de      105\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"country\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06ef2c7",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- The country with the most reported UFO sightings is the United States (U.S.). \n",
    "- Why are sightings so heavily concentrated in the U.S.? \n",
    "- Does this reflect true frequency, reporting behavior, population size, or data collection bias? \n",
    "- To what extent might variables such as a larger population equipped with advanced technology (for instance, internet access and recording devices), or increased interest from organizations like MUFON and NUFORC, contribute to observational or reporting biases regarding UFO phenomena?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bba5103",
   "metadata": {},
   "source": [
    "#### 3.5.3 U.S. States with the Most Sightings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "237a6119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "ca    9655\n",
       "wa    4268\n",
       "fl    4200\n",
       "tx    3677\n",
       "ny    3219\n",
       "az    2689\n",
       "il    2645\n",
       "pa    2582\n",
       "oh    2425\n",
       "mi    2071\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"state\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4088b43",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- According to our data, UFO reported sightings in the U.S. are most likely to occur in California, Washington, Florida, and Texas.\n",
    "- Comparing sightings across different states, California overwhelmingly stands out. \n",
    "- Is California's high count due to population size, visibility conditions, reporting culture, or dataset bias? \n",
    "- Certain UFO shapes (e.g., \"light\", \"triangle\", and \"circle\") are reported more often than others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680fa91a",
   "metadata": {},
   "source": [
    "#### 3.5.4 Most Frequent Datetime Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "de549516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime\n",
       "2010-07-04 22:00:00    36\n",
       "2012-07-04 22:00:00    31\n",
       "1999-11-16 19:00:00    27\n",
       "2009-09-19 20:00:00    26\n",
       "2011-07-04 22:00:00    25\n",
       "2004-10-31 20:00:00    23\n",
       "2010-07-04 21:00:00    23\n",
       "2013-07-04 22:00:00    22\n",
       "2012-07-04 22:30:00    21\n",
       "1999-11-16 19:05:00    20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"datetime\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f1e33",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- Why do certain timestamps appear frequently? \n",
    "- What was happening historically during these times/dates? \n",
    "- Further analyses may concentrate on the years with the highest frequency of reported sightings, allowing for closer examination of these subsets and comparative analysis across different years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0aab4e",
   "metadata": {},
   "source": [
    "### 3.6 Missing Values Check\n",
    "\n",
    "The following section represents early data quality checks; full cleaning will occur in later phases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b09cbdf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                   0\n",
       "city                       0\n",
       "state                   5797\n",
       "country                 9670\n",
       "shape                   1932\n",
       "duration (seconds)         0\n",
       "duration (hours/min)       0\n",
       "comments                  15\n",
       "date posted                0\n",
       "latitude                   0\n",
       "longitude                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifying Missing Values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92712cc1",
   "metadata": {},
   "source": [
    "**Notes**: \n",
    "- Several columns contain missing values, especially those related to location fields (e.g., state & country). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb2cf52",
   "metadata": {},
   "source": [
    "### 3.7 Duplicate Records Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "613fdde8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470b6840",
   "metadata": {},
   "source": [
    "## 4. Initial Observations and Guiding Questions:\n",
    "\n",
    "**A. Data Observations:**\n",
    "- most columns are categorical (\"object\"), type conversion will be necessary for time-based and numerical analysis.\n",
    "- missing values need to be addressed, specifically (\"State\" and \"Country\") to obtain accurate geographic comparisons.\n",
    "- \"Duration\" data will need to be standardized due to inconsistent formatting before analysis.\n",
    "- Reported UFO sightings seemed to be heavily concentrated in the U.S., especially California. This needs to be noted and investigated to determine if reporting bias has occurred.  \n",
    "\n",
    "**B. Guiding Questions:**\n",
    "\n",
    "The following questions focus on temporal, geographic, and descriptive patterns:\n",
    "\n",
    "1. How have reported UFO sightings changed over time (by year and decade), and are there observable global trends?\n",
    "2. Are increases in sightings consistent across countries, or are they primarily driven by reports from the United States?\n",
    "3. Are certain UFO shapes more commonly reported in specific geographic regions?\n",
    "4. Do reported UFO shapes vary across different time periods or decades?\n",
    "5. What temporal patterns exist in UFO sightings (e.g., time of day, seasonality)?\n",
    "6. Are certain UFO shapes associated with longer or shorter reported sighting durations?\n",
    "7. Does the concentration of sightings in the U.S. appear stable over time, or does it fluctuate across decades?\n",
    "8. To what extent might reporting frequency be influenced by population density, access to technology, or cultural factors, as inferred through geographic patterns?\n",
    "\n",
    "**C. Extended & Future Questions Beyond the Current Dataset:**\n",
    "\n",
    "The following questions fall outside the scope of the current dataset and are noted as potential long-term extensions requiring additional external data sources:\n",
    "\n",
    "1. Are reported UFO sightings more common near military bases or government facilities?\n",
    "2. Is there a geographic relationship between reported UFO sightings and reported cattle mutilation incidents?\n",
    "3. Given that “UFO” is a broad classification, are there external datasets that could help refine categories (e.g., UAPs \"Unidentified Aerial Phenomenon\", USOs \"Unidentified Submerged Object\", interdimensional, or other unidentified phenomena) beyond simple shape descriptions?\n",
    "4. Can additional datasets help contextualize sightings using environmental, military, or atmospheric data to move beyond descriptive classifications?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7ee3c2",
   "metadata": {},
   "source": [
    "## 5. Data Cleaning & Preparation for EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2190f048",
   "metadata": {},
   "source": [
    "### 5.1 Hidden Missing Values Detection\n",
    "Objective:\n",
    "Identify non-standard missing-value placeholders to safely replace them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3f33281e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                   0\n",
       "city                      43\n",
       "state                   5797\n",
       "country                 9670\n",
       "shape                   7516\n",
       "duration (seconds)         0\n",
       "duration (hours/min)       0\n",
       "comments                  16\n",
       "date posted                0\n",
       "latitude                   0\n",
       "longitude                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define all hidden missing-value patterns: \n",
    "\n",
    "hidden_missing = [\n",
    "    \"\", \" \", \"  \", \"   \", \n",
    "    \"?\", \"??\", \"-\", \"--\", \"---\",\n",
    "    \"unknown\", \"Unknown\",\n",
    "    \"n/a\", \"N/A\", \"na\", \"NA\",\n",
    "    \"none\", \"None\",\n",
    "    \"null\", \"Null\",\n",
    "    \".\", \"..\", \"...\",\n",
    "    \"nan\", \"NaN\"\n",
    "]\n",
    "\n",
    "# Count hidden missing values in each column before replacement\n",
    "hidden_counts = df.apply(lambda col: col.astype(str).isin(hidden_missing).sum())\n",
    "hidden_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fddfb8e",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- The raw dataset contains many non-standard missing-value placeholders such as \"?\", \"na\", \"none\", and text variations like \"Unknown\".\n",
    "- These must be identified and replaced to avoid incorrect type conversion or misleading summary statistics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6b3faa",
   "metadata": {},
   "source": [
    "### 5.2 Standardizing Missing Values to NaN\n",
    "\n",
    "Objective: Convert all invalid placeholder entries to proper NaN, enabling consistent downstream processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b4e86bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace hidden missing values with np.nan\n",
    "df = df.replace(hidden_missing, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ef20e7",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- Replacing invalid entries with NaN ensures pandas correctly detects missing data (i.e., converting columns to datetime or numeric formats in later phases)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d965b8",
   "metadata": {},
   "source": [
    "### 5.3 Verify Missing Value Fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c7df331e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                   0\n",
       "city                      43\n",
       "state                   5797\n",
       "country                 9670\n",
       "shape                   7516\n",
       "duration (seconds)         0\n",
       "duration (hours/min)       0\n",
       "comments                  16\n",
       "date posted                0\n",
       "latitude                   0\n",
       "longitude                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recalcuate missing values after replacement \n",
    "missing_after_cleanup = df.isna().sum()\n",
    "\n",
    "missing_after_cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe331ef",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- Some columns (e.g. \"state\" and \"country\") still contain legitimate missing values after replacing placeholders.\n",
    "- True missing values will be addressed in the geographic cleanup step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83519dc3",
   "metadata": {},
   "source": [
    "### 5.4 Check Missing Value Percentages\n",
    "\n",
    "This summary shows the percentage of missing values in each column after replacing hidden palceholders with NaN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ccd62c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                 0.00\n",
       "city                     0.05\n",
       "state                    7.22\n",
       "country                 12.04\n",
       "shape                    9.36\n",
       "duration (seconds)       0.00\n",
       "duration (hours/min)     0.00\n",
       "comments                 0.02\n",
       "date posted              0.00\n",
       "latitude                 0.00\n",
       "longitude                0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of missing values per column \n",
    "missing_pct = (df.isna().sum() / len(df) * 100).round(2)\n",
    "missing_pct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e568b5f",
   "metadata": {},
   "source": [
    "**Notes**: \"country\" (12.04%), \"shape\" (9.36%), and \"state\" (7.22%) represent the highest % of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd58bf94",
   "metadata": {},
   "source": [
    "### 5.5 Geographic Cleanup\n",
    "\n",
    "Objective: Before using latitude/longitude to infer missing locations, clean the fields so only true missing values remain.\n",
    "\n",
    "*Note: \"unknown\" = term is used as a temporary placeholder, proper geospatial inference will replace these later.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56aedf9",
   "metadata": {},
   "source": [
    "#### 5.5a Inspect Missing Geographic Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "ead10fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state      5797\n",
       "country    9670\n",
       "dtype: int64"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing geographic fields\n",
    "geo_missing = df[[\"state\", \"country\"]].isna().sum()\n",
    "geo_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f49d0a",
   "metadata": {},
   "source": [
    "**Notes**: \n",
    "- The high count of missing UFO-sighting location data for states (5,797) and country (9,670) indicates that the geographic info is incomplete in my records.\n",
    "\n",
    "- The numerous missing \"state\" and \"country\" values confirm that many geographic fields were not originally standardized. \n",
    "- These missing values will require inference later (via coordinates and shapefile-based spatial joins)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1093ec70",
   "metadata": {},
   "source": [
    "#### 5.5b Standardize Geographic Fields\n",
    "\n",
    "Purpose: Ensure \"state\" and \"country\" values are consistently formatted (lowercase, no whitespace) so comparisons and merging efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d64b601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize\"state\" and \"country\" fields\n",
    "for col in [\"state\", \"country\"]:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(\"string\")\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .replace(\"\", pd.NA)\n",
    "        .replace(\"?\", pd.NA)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad92b37",
   "metadata": {},
   "source": [
    "**Note:** \n",
    "- \"state\" and \"country\" converted to a consistent text format (i.e., lowercase, trimmed).\n",
    "- Replaces empty or invalid strings so missing values are accurately recognized. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d964c65",
   "metadata": {},
   "source": [
    "#### 5.5c Fill Temporary \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "13acda25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"state\"] = df[\"state\"].fillna(\"unknown\")\n",
    "df[\"country\"] = df[\"country\"].fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43806d5e",
   "metadata": {},
   "source": [
    "**Note:** \n",
    "- \"unknown\" is used as a temporary placeholder so that missing values can be tracked.\n",
    "- Spatial joins in Section 7 will replace unknown entries with accurate geographic assignments/lookup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59be3548",
   "metadata": {},
   "source": [
    "#### 5.5d Verify Fixes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "afcaa598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state      0\n",
       "country    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Missing Datetime Count Again\n",
    "df[[\"state\", \"country\"]].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303db61e",
   "metadata": {},
   "source": [
    "**Note:** Confirmed no blank or invalid geographic values remain after standardization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7f68ca",
   "metadata": {},
   "source": [
    "## 6. Import Geopandas & Load Shapefiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3e4495",
   "metadata": {},
   "source": [
    "### 6.1 Import GeoPandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0bf156fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e987d3",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- GeoPandas is required for geospatial and mapping. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d858a",
   "metadata": {},
   "source": [
    "### 6.2 Load World & U.S. Shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "359bd636",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_path = \"../data/shapefiles/world/ne_50m_admin_0_countries.shp\"\n",
    "gdf_world = gpd.read_file(world_path)\n",
    "\n",
    "states_path = \"../data/shapefiles/us_states/cb_2022_us_state_5m.shp\"\n",
    "gdf_states = gpd.read_file(states_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d1bf00",
   "metadata": {},
   "source": [
    "**Notes**: The shapefiles corresponding to world layers (\"world_path\") and state layers (\"state_path\") supply the necessary polygon data required for accurately mapping UFO sightings by country and by U.S. state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bd9b3c",
   "metadata": {},
   "source": [
    "### 6.3 Preview the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "2e184523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        featurecla  scalerank  LABELRANK SOVEREIGNT SOV_A3  ADM0_DIF  LEVEL  \\\n",
       " 0  Admin-0 country          1          3   Zimbabwe    ZWE         0      2   \n",
       " 1  Admin-0 country          1          3     Zambia    ZMB         0      2   \n",
       " 2  Admin-0 country          1          3      Yemen    YEM         0      2   \n",
       " 3  Admin-0 country          3          2    Vietnam    VNM         0      2   \n",
       " 4  Admin-0 country          5          3  Venezuela    VEN         0      2   \n",
       " \n",
       "                 TYPE TLC      ADMIN  ... FCLASS_TR  FCLASS_ID FCLASS_PL  \\\n",
       " 0  Sovereign country   1   Zimbabwe  ...      None       None      None   \n",
       " 1  Sovereign country   1     Zambia  ...      None       None      None   \n",
       " 2  Sovereign country   1      Yemen  ...      None       None      None   \n",
       " 3  Sovereign country   1    Vietnam  ...      None       None      None   \n",
       " 4  Sovereign country   1  Venezuela  ...      None       None      None   \n",
       " \n",
       "   FCLASS_GR  FCLASS_IT FCLASS_NL FCLASS_SE  FCLASS_BD FCLASS_UA  \\\n",
       " 0      None       None      None      None       None      None   \n",
       " 1      None       None      None      None       None      None   \n",
       " 2      None       None      None      None       None      None   \n",
       " 3      None       None      None      None       None      None   \n",
       " 4      None       None      None      None       None      None   \n",
       " \n",
       "                                             geometry  \n",
       " 0  POLYGON ((31.28789 -22.40205, 31.19727 -22.344...  \n",
       " 1  POLYGON ((30.39609 -15.64307, 30.25068 -15.643...  \n",
       " 2  MULTIPOLYGON (((53.08564 16.64839, 52.58145 16...  \n",
       " 3  MULTIPOLYGON (((104.06396 10.39082, 104.08301 ...  \n",
       " 4  MULTIPOLYGON (((-60.82119 9.13838, -60.94141 9...  \n",
       " \n",
       " [5 rows x 169 columns],\n",
       "   STATEFP   STATENS     AFFGEOID GEOID STUSPS         NAME LSAD         ALAND  \\\n",
       " 0      35  00897535  0400000US35    35     NM   New Mexico   00  314198573403   \n",
       " 1      72  01779808  0400000US72    72     PR  Puerto Rico   00    8869029522   \n",
       " 2      48  01779801  0400000US48    48     TX        Texas   00  676685555821   \n",
       " 3      21  01779786  0400000US21    21     KY     Kentucky   00  102266581101   \n",
       " 4      39  01085497  0400000US39    39     OH         Ohio   00  105823621267   \n",
       " \n",
       "         AWATER                                           geometry  \n",
       " 0    726463825  POLYGON ((-109.05017 31.48, -109.04984 31.4995...  \n",
       " 1   4922249087  MULTIPOLYGON (((-65.3357 18.34954, -65.32933 1...  \n",
       " 2  18974391187  POLYGON ((-106.64548 31.89867, -106.64084 31.9...  \n",
       " 3   2384240769  MULTIPOLYGON (((-89.40565 36.52816, -89.39868 ...  \n",
       " 4  10274734976  MULTIPOLYGON (((-82.73571 41.60336, -82.72309 ...  )"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_world.head(), gdf_states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "13928deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STATEFP', 'STATENS', 'AFFGEOID', 'GEOID', 'STUSPS', 'NAME', 'LSAD',\n",
       "       'ALAND', 'AWATER', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_states.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6f7f277c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATEFP</th>\n",
       "      <th>STATENS</th>\n",
       "      <th>AFFGEOID</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>STUSPS</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LSAD</th>\n",
       "      <th>ALAND</th>\n",
       "      <th>AWATER</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>00897535</td>\n",
       "      <td>0400000US35</td>\n",
       "      <td>35</td>\n",
       "      <td>NM</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>00</td>\n",
       "      <td>314198573403</td>\n",
       "      <td>726463825</td>\n",
       "      <td>POLYGON ((-109.05017 31.48, -109.04984 31.4995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>01779808</td>\n",
       "      <td>0400000US72</td>\n",
       "      <td>72</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>00</td>\n",
       "      <td>8869029522</td>\n",
       "      <td>4922249087</td>\n",
       "      <td>MULTIPOLYGON (((-65.3357 18.34954, -65.32933 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>01779801</td>\n",
       "      <td>0400000US48</td>\n",
       "      <td>48</td>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "      <td>00</td>\n",
       "      <td>676685555821</td>\n",
       "      <td>18974391187</td>\n",
       "      <td>POLYGON ((-106.64548 31.89867, -106.64084 31.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>01779786</td>\n",
       "      <td>0400000US21</td>\n",
       "      <td>21</td>\n",
       "      <td>KY</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>00</td>\n",
       "      <td>102266581101</td>\n",
       "      <td>2384240769</td>\n",
       "      <td>MULTIPOLYGON (((-89.40565 36.52816, -89.39868 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>01085497</td>\n",
       "      <td>0400000US39</td>\n",
       "      <td>39</td>\n",
       "      <td>OH</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>00</td>\n",
       "      <td>105823621267</td>\n",
       "      <td>10274734976</td>\n",
       "      <td>MULTIPOLYGON (((-82.73571 41.60336, -82.72309 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STATEFP   STATENS     AFFGEOID GEOID STUSPS         NAME LSAD         ALAND  \\\n",
       "0      35  00897535  0400000US35    35     NM   New Mexico   00  314198573403   \n",
       "1      72  01779808  0400000US72    72     PR  Puerto Rico   00    8869029522   \n",
       "2      48  01779801  0400000US48    48     TX        Texas   00  676685555821   \n",
       "3      21  01779786  0400000US21    21     KY     Kentucky   00  102266581101   \n",
       "4      39  01085497  0400000US39    39     OH         Ohio   00  105823621267   \n",
       "\n",
       "        AWATER                                           geometry  \n",
       "0    726463825  POLYGON ((-109.05017 31.48, -109.04984 31.4995...  \n",
       "1   4922249087  MULTIPOLYGON (((-65.3357 18.34954, -65.32933 1...  \n",
       "2  18974391187  POLYGON ((-106.64548 31.89867, -106.64084 31.9...  \n",
       "3   2384240769  MULTIPOLYGON (((-89.40565 36.52816, -89.39868 ...  \n",
       "4  10274734976  MULTIPOLYGON (((-82.73571 41.60336, -82.72309 ...  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_states.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0e2d96",
   "metadata": {},
   "source": [
    "**Notes**: .head() confirms that the geometry fields loaded correctly and the files were read successfully. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01d2707",
   "metadata": {},
   "source": [
    "### 6.4 Check CRS (Coordinate Reference Systems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "3b767048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Geographic 2D CRS: EPSG:4326>\n",
       " Name: WGS 84\n",
       " Axis Info [ellipsoidal]:\n",
       " - Lat[north]: Geodetic latitude (degree)\n",
       " - Lon[east]: Geodetic longitude (degree)\n",
       " Area of Use:\n",
       " - name: World.\n",
       " - bounds: (-180.0, -90.0, 180.0, 90.0)\n",
       " Datum: World Geodetic System 1984 ensemble\n",
       " - Ellipsoid: WGS 84\n",
       " - Prime Meridian: Greenwich,\n",
       " <Geographic 2D CRS: EPSG:4326>\n",
       " Name: WGS 84\n",
       " Axis Info [ellipsoidal]:\n",
       " - Lat[north]: Geodetic latitude (degree)\n",
       " - Lon[east]: Geodetic longitude (degree)\n",
       " Area of Use:\n",
       " - name: World.\n",
       " - bounds: (-180.0, -90.0, 180.0, 90.0)\n",
       " Datum: World Geodetic System 1984 ensemble\n",
       " - Ellipsoid: WGS 84\n",
       " - Prime Meridian: Greenwich)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_world.crs, gdf_states.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b3ea4a",
   "metadata": {},
   "source": [
    "**Notes**: \n",
    "-\tU.S. Census shapefiles use NAD83, but NAD83 is not the same as WGS 84. Cannot special-join layers with different CRS. \n",
    "-\tShapefiles must share the same CRS before spatial joins or plotting. \n",
    "-\tThe world layer uses EPSG:4326, but the U.S. states layer uses EPSG:4269, requiring re-projection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0880f6e",
   "metadata": {},
   "source": [
    "### 6.5 Reproject U.S. States to Match World CRS (EPSG:4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "8ef4afc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Geographic 2D CRS: EPSG:4326>\n",
       "Name: WGS 84\n",
       "Axis Info [ellipsoidal]:\n",
       "- Lat[north]: Geodetic latitude (degree)\n",
       "- Lon[east]: Geodetic longitude (degree)\n",
       "Area of Use:\n",
       "- name: World.\n",
       "- bounds: (-180.0, -90.0, 180.0, 90.0)\n",
       "Datum: World Geodetic System 1984 ensemble\n",
       "- Ellipsoid: WGS 84\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_states = gdf_states.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Verify change\n",
    "gdf_states.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f5bf1",
   "metadata": {},
   "source": [
    "**Notes**: \n",
    "- The U.S. states layer is now aligned with global coordinates.\n",
    "- After reprojection, both world and U.S. layers share EPSG:4326, enabling accurate spatial operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4300d732",
   "metadata": {},
   "source": [
    "## 7. Convert UFO Coordinates Into Geographic Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f74bd8",
   "metadata": {},
   "source": [
    "### 7.1 Clean Column Names \n",
    "\n",
    "Purpose: Some column names contain trailing spaces, which break merge operations and comparisons. Stripping whitespace ensures consistent behavior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "38d2df45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'city', 'state', 'country', 'shape', 'duration (seconds)',\n",
       "       'duration (hours/min)', 'comments', 'date posted', 'latitude',\n",
       "       'longitude'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove leading/trailing spaces in column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2e1c38",
   "metadata": {},
   "source": [
    "**Note**: clean column names to prevent merge failures caused by trailing spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bfecd3",
   "metadata": {},
   "source": [
    "### 7.2 Import Point/Geo Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "f62d3770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Point and geopandas\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cb5180",
   "metadata": {},
   "source": [
    "**Note**: GeoPandas and Shapely are required to convert latitude/longitude into point geometries. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bc9a20",
   "metadata": {},
   "source": [
    "### 7.3 Clean Latitude & Longitude\n",
    "\n",
    "Purpose: Convert text coordinates to numeric values and detect invalid entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "0b2a7c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude     1\n",
       "longitude    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert latitude & longitude to numeric (fix invalid values)\n",
    "df[\"latitude\"] = pd.to_numeric(df[\"latitude\"], errors=\"coerce\")\n",
    "df[\"longitude\"] = pd.to_numeric(df[\"longitude\"], errors=\"coerce\")\n",
    "\n",
    "# Check how many coordinates are missing\n",
    "df[[\"latitude\", \"longitude\"]].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1befd209",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- Only one invalid latitude value was converted to NaN and manually corrected..\n",
    "- Missing (NaN) or invalid values were converted into NaN during pd.to_numeric(..., errors=\"coerce\")\n",
    "- All coordinates now numeric -> required for mapping and spatial joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "4756c9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>comments</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43782</th>\n",
       "      <td>1974-05-22 05:30:00</td>\n",
       "      <td>mescalero indian reservation</td>\n",
       "      <td>nm</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Huge rectangular object emmitting intense whit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-105.624152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime                          city state  country  \\\n",
       "43782  1974-05-22 05:30:00  mescalero indian reservation    nm  unknown   \n",
       "\n",
       "                                                comments  latitude   longitude  \n",
       "43782  Huge rectangular object emmitting intense whit...       NaN -105.624152  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show specific column values with missing latitude\n",
    "df[df[\"latitude\"].isna()][[\"datetime\", \"city\", \"state\", \"country\", \"comments\", \"latitude\", \"longitude\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "6029a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mescalero Indian Reservation latitude:\n",
    "df.loc[43782, \"latitude\"] = 33.33\n",
    "df.loc[43782, \"country\"] = \"us\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "674765b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city         mescalero indian reservation\n",
       "state                                  nm\n",
       "country                                us\n",
       "latitude                            33.33\n",
       "longitude                     -105.624152\n",
       "Name: 43782, dtype: object"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verification \n",
    "df.loc[43782][[\"city\", \"state\", \"country\", \"latitude\", \"longitude\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "0ae18530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude     0\n",
       "longitude    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many coordinates are missing\n",
    "df[[\"latitude\", \"longitude\"]].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468dd6d2",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "I decided not to drop the row as I was able to approximate the latitude within a relatively small margin of error as it was located within a specific indian resservation in New Mexico, and the longitude was also provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f194e91",
   "metadata": {},
   "source": [
    "### 7.4 Convert UFO Data Into GeoDataFrame\n",
    "\n",
    "Purpose: Add a geometry column so the dataset can be used in spatial joins, mapping, and geospatial analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "88f61bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-10-10 20:30:00</td>\n",
       "      <td>san marcos</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>2700</td>\n",
       "      <td>45 minutes</td>\n",
       "      <td>This event took place in early fall around 194...</td>\n",
       "      <td>2004-04-27</td>\n",
       "      <td>29.883056</td>\n",
       "      <td>-97.941111</td>\n",
       "      <td>POINT (-97.94111 29.88306)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-10-10 21:00:00</td>\n",
       "      <td>lackland afb</td>\n",
       "      <td>tx</td>\n",
       "      <td>unknown</td>\n",
       "      <td>light</td>\n",
       "      <td>7200</td>\n",
       "      <td>1-2 hrs</td>\n",
       "      <td>1949 Lackland AFB&amp;#44 TX.  Lights racing acros...</td>\n",
       "      <td>2005-12-16</td>\n",
       "      <td>29.384210</td>\n",
       "      <td>-98.581082</td>\n",
       "      <td>POINT (-98.58108 29.38421)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1955-10-10 17:00:00</td>\n",
       "      <td>chester (uk/england)</td>\n",
       "      <td>unknown</td>\n",
       "      <td>gb</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>20 seconds</td>\n",
       "      <td>Green/Orange circular disc over Chester&amp;#44 En...</td>\n",
       "      <td>2008-01-21</td>\n",
       "      <td>53.200000</td>\n",
       "      <td>-2.916667</td>\n",
       "      <td>POINT (-2.91667 53.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956-10-10 21:00:00</td>\n",
       "      <td>edna</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>1/2 hour</td>\n",
       "      <td>My older brother and twin sister were leaving ...</td>\n",
       "      <td>2004-01-17</td>\n",
       "      <td>28.978333</td>\n",
       "      <td>-96.645833</td>\n",
       "      <td>POINT (-96.64583 28.97833)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960-10-10 20:00:00</td>\n",
       "      <td>kaneohe</td>\n",
       "      <td>hi</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>900</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>AS a Marine 1st Lt. flying an FJ4B fighter/att...</td>\n",
       "      <td>2004-01-22</td>\n",
       "      <td>21.418056</td>\n",
       "      <td>-157.803611</td>\n",
       "      <td>POINT (-157.80361 21.41806)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime                  city    state  country     shape  \\\n",
       "0  1949-10-10 20:30:00            san marcos       tx       us  cylinder   \n",
       "1  1949-10-10 21:00:00          lackland afb       tx  unknown     light   \n",
       "2  1955-10-10 17:00:00  chester (uk/england)  unknown       gb    circle   \n",
       "3  1956-10-10 21:00:00                  edna       tx       us    circle   \n",
       "4  1960-10-10 20:00:00               kaneohe       hi       us     light   \n",
       "\n",
       "  duration (seconds) duration (hours/min)  \\\n",
       "0               2700           45 minutes   \n",
       "1               7200              1-2 hrs   \n",
       "2                 20           20 seconds   \n",
       "3                 20             1/2 hour   \n",
       "4                900           15 minutes   \n",
       "\n",
       "                                            comments date posted   latitude  \\\n",
       "0  This event took place in early fall around 194...  2004-04-27  29.883056   \n",
       "1  1949 Lackland AFB&#44 TX.  Lights racing acros...  2005-12-16  29.384210   \n",
       "2  Green/Orange circular disc over Chester&#44 En...  2008-01-21  53.200000   \n",
       "3  My older brother and twin sister were leaving ...  2004-01-17  28.978333   \n",
       "4  AS a Marine 1st Lt. flying an FJ4B fighter/att...  2004-01-22  21.418056   \n",
       "\n",
       "    longitude                     geometry  \n",
       "0  -97.941111   POINT (-97.94111 29.88306)  \n",
       "1  -98.581082   POINT (-98.58108 29.38421)  \n",
       "2   -2.916667        POINT (-2.91667 53.2)  \n",
       "3  -96.645833   POINT (-96.64583 28.97833)  \n",
       "4 -157.803611  POINT (-157.80361 21.41806)  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy to avoid modifying original df\n",
    "gdf_ufo = df.copy()\n",
    "\n",
    "# Create geometry column\n",
    "gdf_ufo[\"geometry\"] = gdf_ufo.apply(\n",
    "    lambda row: Point(row[\"longitude\"], row[\"latitude\"]), axis=1\n",
    ")\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "gdf_ufo = gpd.GeoDataFrame(gdf_ufo, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "# Verification\n",
    "gdf_ufo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcde597",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- One invalid latitude value was converted to NaN and manually corrected.\n",
    "- All coordinates now numeric -> required for mapping and spatial joins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1c26ba",
   "metadata": {},
   "source": [
    "### 7.5 Spatial Join: Assign Countries Automatically\n",
    "\n",
    "Purpose: Match each UFO sighting to a country boundary polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e3591d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>country_filled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>us</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unknown</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gb</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>us</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>us</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country            country_filled\n",
       "0       us  United States of America\n",
       "1  unknown  United States of America\n",
       "2       gb            United Kingdom\n",
       "3       us  United States of America\n",
       "4       us  United States of America"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the world boundry geometry + country name\n",
    "world = gdf_world[[\"ADMIN\", \"geometry\"]].rename(columns={\"ADMIN\": \"country_filled\"})\n",
    "\n",
    "# Spatial join to assign country by position\n",
    "ufo_with_country = gpd.sjoin(\n",
    "    gdf_ufo,\n",
    "    world,\n",
    "    how=\"left\",\n",
    "    predicate=\"within\"\n",
    ")\n",
    "\n",
    "# Inspect results\n",
    "ufo_with_country[[\"country\", \"country_filled\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218221b3",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- The spatial join assigns each UFO sighting to a country’s polygon based on its point coordinates.\n",
    "- Using predicate=\"within\" ensures a point is matched only if it lies inside a country's boundaries.\n",
    "- World country polygons are used to fill out missing or incorrect country labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "2d61db93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'city', 'state', 'country', 'shape', 'duration (seconds)',\n",
       "       'duration (hours/min)', 'comments', 'date posted', 'latitude',\n",
       "       'longitude', 'geometry', 'index_right', 'country_filled'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo_with_country.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c4b98f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leftover index_right column from previous spatial join\n",
    "if \"index_right\" in ufo_with_country.columns:\n",
    "    ufo_with_country = ufo_with_country.drop(columns=[\"index_right\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a8cae",
   "metadata": {},
   "source": [
    "### 7.6 Spatial Join for U.S. States\n",
    "\n",
    "Purpose: Match each U.S. UFO sighting to a state boundry polygon, to render a clean \"state_filled\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f060b7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>state_filled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tx</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tx</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tx</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi</td>\n",
       "      <td>Hawaii</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state state_filled\n",
       "0       tx        Texas\n",
       "1       tx        Texas\n",
       "2  unknown          NaN\n",
       "3       tx        Texas\n",
       "4       hi       Hawaii"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only state name + geometry for U.S. states\n",
    "states = gdf_states[[\"NAME\", \"geometry\"]].rename(columns={\"NAME\": \"state_filled\"})\n",
    "\n",
    "# Spatial join to assign U.S. state by position\n",
    "ufo_with_state = gpd.sjoin(\n",
    "    ufo_with_country,\n",
    "    states,\n",
    "    how=\"left\",\n",
    "    predicate=\"within\"\n",
    ")\n",
    "\n",
    "# Inspect results\n",
    "ufo_with_state[[\"state\", \"state_filled\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71f9d2d",
   "metadata": {},
   "source": [
    "**Note**: This spatial join resolves missing or incorrect U.S. state values by determining the state in which each UFO coordinate falls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7940e18b",
   "metadata": {},
   "source": [
    "### 7.7 Clean & Standardize U.S. States Alphabetically\n",
    "\n",
    "Purpose: Create a standardized mapping between full state names and their two-letter codes to ensure consistency across all future analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "7231be3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alabama': 'al',\n",
       " 'Alaska': 'ak',\n",
       " 'American Samoa': 'as',\n",
       " 'Arizona': 'az',\n",
       " 'Arkansas': 'ar',\n",
       " 'California': 'ca',\n",
       " 'Colorado': 'co',\n",
       " 'Commonwealth of the Northern Mariana Islands': 'mp',\n",
       " 'Connecticut': 'ct',\n",
       " 'Delaware': 'de',\n",
       " 'District of Columbia': 'dc',\n",
       " 'Florida': 'fl',\n",
       " 'Georgia': 'ga',\n",
       " 'Guam': 'gu',\n",
       " 'Hawaii': 'hi',\n",
       " 'Idaho': 'id',\n",
       " 'Illinois': 'il',\n",
       " 'Indiana': 'in',\n",
       " 'Iowa': 'ia',\n",
       " 'Kansas': 'ks',\n",
       " 'Kentucky': 'ky',\n",
       " 'Louisiana': 'la',\n",
       " 'Maine': 'me',\n",
       " 'Maryland': 'md',\n",
       " 'Massachusetts': 'ma',\n",
       " 'Michigan': 'mi',\n",
       " 'Minnesota': 'mn',\n",
       " 'Mississippi': 'ms',\n",
       " 'Missouri': 'mo',\n",
       " 'Montana': 'mt',\n",
       " 'Nebraska': 'ne',\n",
       " 'Nevada': 'nv',\n",
       " 'New Hampshire': 'nh',\n",
       " 'New Jersey': 'nj',\n",
       " 'New Mexico': 'nm',\n",
       " 'New York': 'ny',\n",
       " 'North Carolina': 'nc',\n",
       " 'North Dakota': 'nd',\n",
       " 'Ohio': 'oh',\n",
       " 'Oklahoma': 'ok',\n",
       " 'Oregon': 'or',\n",
       " 'Pennsylvania': 'pa',\n",
       " 'Puerto Rico': 'pr',\n",
       " 'Rhode Island': 'ri',\n",
       " 'South Carolina': 'sc',\n",
       " 'South Dakota': 'sd',\n",
       " 'Tennessee': 'tn',\n",
       " 'Texas': 'tx',\n",
       " 'United States Virgin Islands': 'vi',\n",
       " 'Utah': 'ut',\n",
       " 'Vermont': 'vt',\n",
       " 'Virginia': 'va',\n",
       " 'Washington': 'wa',\n",
       " 'West Virginia': 'wv',\n",
       " 'Wisconsin': 'wi',\n",
       " 'Wyoming': 'wy'}"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build mapping automatically from shapefile in alphabetical order\n",
    "state_name_to_code = (\n",
    "    gdf_states.set_index(\"NAME\")[\"STUSPS\"]\n",
    "    .str.lower()    # convert to lowercase for consistency\n",
    "    .sort_index()  # sorts alphabetically by state name\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "state_name_to_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a037edbe",
   "metadata": {},
   "source": [
    "**Note**: Generated a dictionary to convert state names to standardized 2-letter USPS codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c268f8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state_final\n",
       "<class 'str'>    80332\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix list-type states: convert [\"texas\"] --> \"texas\"\n",
    "ufo_clean[\"state_final\"] = ufo_clean[\"state_final\"].apply(\n",
    "    lambda x: x[0] if isinstance(x, list) and len(x) > 0 else x\n",
    ")\n",
    "\n",
    "# Verifty fix\n",
    "ufo_clean[\"state_final\"].apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1841c029",
   "metadata": {},
   "source": [
    "### 7.8 Create a Cleaned & Standardized state column\n",
    "\n",
    "Purpose: Combine original state values with shapefile-derived values to produce one final, reliable state column for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "eb89b1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>state_filled</th>\n",
       "      <th>state_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tx</td>\n",
       "      <td>texas</td>\n",
       "      <td>tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tx</td>\n",
       "      <td>texas</td>\n",
       "      <td>tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unknown</td>\n",
       "      <td>nan</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tx</td>\n",
       "      <td>texas</td>\n",
       "      <td>tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi</td>\n",
       "      <td>hawaii</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state state_filled state_final\n",
       "0       tx        texas          tx\n",
       "1       tx        texas          tx\n",
       "2  unknown          nan     unknown\n",
       "3       tx        texas          tx\n",
       "4       hi       hawaii          hi"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a safe working copy of the UFO dataframe to avoid overwriting earlier versions\n",
    "ufo_clean = ufo_with_state.copy()\n",
    "\n",
    "# Lowercase both \"state\" and \"state_filled\" to ensure comparisons are consistent\n",
    "ufo_clean[\"state\"] = ufo_clean[\"state\"].astype(str).str.lower()\n",
    "ufo_clean[\"state_filled\"] = ufo_clean[\"state_filled\"].astype(str).str.lower()\n",
    "\n",
    "# Build final state - Define function to resolve the final state value\n",
    "def resolve_state(row):\n",
    "    state = row[\"state\"]\n",
    "    filled = row[\"state_filled\"]\n",
    "\n",
    "    # If original state is missing or labeled as unknown\n",
    "    if state in [\"unknown\", \"\", None] or pd.isna(state) or state == \"nan\":\n",
    "\n",
    "        # If shapefile successfully assigned as state\n",
    "        if filled not in [\"nan\", \"none\", \"\", None] and not pd.isna(filled):\n",
    "            return filled\n",
    "        else:\n",
    "            return \"unknown\"   # Last resort if no info was found anywhere\n",
    "    # Otherwise: keep original state (already standardized)\n",
    "    return state\n",
    "\n",
    "# Apply the state resolution function -> creates a clean final state column\n",
    "ufo_clean[\"state_final\"] = ufo_clean.apply(resolve_state, axis=1)\n",
    "\n",
    "# Preview Results\n",
    "ufo_clean[[\"state\", \"state_filled\", \"state_final\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288a1857",
   "metadata": {},
   "source": [
    "**Note**: The final state_final column merges original and inferred values for best accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a9c327",
   "metadata": {},
   "source": [
    "**Logic:**\n",
    "- If orginal state is missing -> use shapefile-dervied state_filled\n",
    "- If shapefile value is available -> prefer state_filled\n",
    "- If everything fails -> return \"unknown\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c898810",
   "metadata": {},
   "source": [
    "### 7.9 Validate All Unique State Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "cb0a2b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'city', 'state', 'country', 'shape', 'duration (seconds)',\n",
       "       'duration (hours/min)', 'comments', 'date posted', 'latitude',\n",
       "       'longitude', 'geometry', 'country_filled', 'index_right',\n",
       "       'state_filled', 'state_final'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "427eb96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab',\n",
       " 'ak',\n",
       " 'al',\n",
       " 'alabama',\n",
       " 'ar',\n",
       " 'arizona',\n",
       " 'arkansas',\n",
       " 'az',\n",
       " 'bc',\n",
       " 'ca',\n",
       " 'california',\n",
       " 'co',\n",
       " 'colorado',\n",
       " 'connecticut',\n",
       " 'ct',\n",
       " 'dc',\n",
       " 'de',\n",
       " 'fl',\n",
       " 'florida',\n",
       " 'ga',\n",
       " 'georgia',\n",
       " 'guam',\n",
       " 'hi',\n",
       " 'ia',\n",
       " 'id',\n",
       " 'il',\n",
       " 'in',\n",
       " 'kansas',\n",
       " 'kentucky',\n",
       " 'ks',\n",
       " 'ky',\n",
       " 'la',\n",
       " 'louisiana',\n",
       " 'ma',\n",
       " 'massachusetts',\n",
       " 'mb',\n",
       " 'md',\n",
       " 'me',\n",
       " 'mi',\n",
       " 'michigan',\n",
       " 'mississippi',\n",
       " 'missouri',\n",
       " 'mn',\n",
       " 'mo',\n",
       " 'montana',\n",
       " 'ms',\n",
       " 'mt',\n",
       " 'nb',\n",
       " 'nc',\n",
       " 'nd',\n",
       " 'ne',\n",
       " 'nevada',\n",
       " 'new jersey',\n",
       " 'new mexico',\n",
       " 'new york',\n",
       " 'nf',\n",
       " 'nh',\n",
       " 'nj',\n",
       " 'nm',\n",
       " 'north carolina',\n",
       " 'ns',\n",
       " 'nt',\n",
       " 'nv',\n",
       " 'ny',\n",
       " 'oh',\n",
       " 'ohio',\n",
       " 'ok',\n",
       " 'on',\n",
       " 'or',\n",
       " 'oregon',\n",
       " 'pa',\n",
       " 'pe',\n",
       " 'pennsylvania',\n",
       " 'pq',\n",
       " 'pr',\n",
       " 'puerto rico',\n",
       " 'qc',\n",
       " 'ri',\n",
       " 'sa',\n",
       " 'sc',\n",
       " 'sd',\n",
       " 'sk',\n",
       " 'south carolina',\n",
       " 'texas',\n",
       " 'tn',\n",
       " 'tx',\n",
       " 'united states virgin islands',\n",
       " 'unknown',\n",
       " 'ut',\n",
       " 'va',\n",
       " 'virginia',\n",
       " 'vt',\n",
       " 'wa',\n",
       " 'washington',\n",
       " 'west virginia',\n",
       " 'wi',\n",
       " 'wv',\n",
       " 'wy',\n",
       " 'wyoming',\n",
       " 'yk',\n",
       " 'yt']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review all unique state codes\n",
    "sorted(ufo_clean[\"state_final\"].dropna().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5982ee74",
   "metadata": {},
   "source": [
    "**Note**: Validating unique values ensures the final state column contains only standardized and expected codes after the cleaning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "2a335b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state_final\n",
       "ca                9655\n",
       "unknown           5685\n",
       "wa                4268\n",
       "fl                4200\n",
       "tx                3677\n",
       "                  ... \n",
       "nevada               1\n",
       "guam                 1\n",
       "new york             1\n",
       "montana              1\n",
       "north carolina       1\n",
       "Name: count, Length: 101, dtype: int64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count occurances of each state\n",
    "ufo_clean[\"state_final\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "e2ec2e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unknown',\n",
       " 'missouri',\n",
       " 'alabama',\n",
       " 'colorado',\n",
       " 'texas',\n",
       " 'connecticut',\n",
       " 'arkansas',\n",
       " 'kansas',\n",
       " 'south carolina',\n",
       " 'ohio',\n",
       " 'puerto rico',\n",
       " 'new mexico',\n",
       " 'florida',\n",
       " 'arizona',\n",
       " 'united states virgin islands',\n",
       " 'mississippi',\n",
       " 'michigan',\n",
       " 'wyoming',\n",
       " 'oregon',\n",
       " 'virginia',\n",
       " 'kentucky',\n",
       " 'california',\n",
       " 'louisiana',\n",
       " 'pennsylvania',\n",
       " 'georgia',\n",
       " 'washington',\n",
       " 'nevada',\n",
       " 'massachusetts',\n",
       " 'new jersey',\n",
       " 'west virginia',\n",
       " 'guam',\n",
       " 'new york',\n",
       " 'montana',\n",
       " 'north carolina']"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for invalid 3+ letter state values\n",
    "invalid_states = [s for s in ufo_clean[\"state_final\"].unique() if isinstance(s, str) and len(s) > 2]\n",
    "invalid_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e949a4a",
   "metadata": {},
   "source": [
    "**Note**: Confirmed that all states are valid USPS codes or \"unknown\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6c47d4",
   "metadata": {},
   "source": [
    "### 7.10 Convert State Names into 2-Letter Codes\n",
    "\n",
    "Purpose: Standardize all U.S. state values to consistent 2-letter codes so they can be merged, grouped, and mapped reliably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a8967e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab',\n",
       " 'ak',\n",
       " 'al',\n",
       " 'ar',\n",
       " 'az',\n",
       " 'bc',\n",
       " 'ca',\n",
       " 'co',\n",
       " 'ct',\n",
       " 'dc',\n",
       " 'de',\n",
       " 'fl',\n",
       " 'ga',\n",
       " 'gu',\n",
       " 'hi',\n",
       " 'ia',\n",
       " 'id',\n",
       " 'il',\n",
       " 'in',\n",
       " 'ks',\n",
       " 'ky',\n",
       " 'la',\n",
       " 'ma',\n",
       " 'mb',\n",
       " 'md',\n",
       " 'me',\n",
       " 'mi',\n",
       " 'mn',\n",
       " 'mo',\n",
       " 'ms',\n",
       " 'mt',\n",
       " 'nb',\n",
       " 'nc',\n",
       " 'nd',\n",
       " 'ne',\n",
       " 'nf',\n",
       " 'nh',\n",
       " 'nj',\n",
       " 'nm',\n",
       " 'ns',\n",
       " 'nt',\n",
       " 'nv',\n",
       " 'ny',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'on',\n",
       " 'or',\n",
       " 'pa',\n",
       " 'pe',\n",
       " 'pq',\n",
       " 'pr',\n",
       " 'qc',\n",
       " 'ri',\n",
       " 'sa',\n",
       " 'sc',\n",
       " 'sd',\n",
       " 'sk',\n",
       " 'tn',\n",
       " 'tx',\n",
       " 'unknown',\n",
       " 'ut',\n",
       " 'va',\n",
       " 'vi',\n",
       " 'vt',\n",
       " 'wa',\n",
       " 'wi',\n",
       " 'wv',\n",
       " 'wy',\n",
       " 'yk',\n",
       " 'yt']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to string\n",
    "ufo_clean[\"state_final\"] = ufo_clean[\"state_final\"].astype(str)\n",
    "\n",
    "# Convert full names --> abbreviations using dictionary\n",
    "ufo_clean[\"state_final\"] = ufo_clean[\"state_final\"].map(\n",
    "    lambda x: state_name_to_code.get(x.strip().title(), x.lower())\n",
    ")\n",
    "\n",
    "# Validate \n",
    "sorted(ufo_clean[\"state_final\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f110f9",
   "metadata": {},
   "source": [
    "**Note**: The sorted results confirm that all states have been converted into lowercase 2-letter codes with no remaining full names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "6a7b5949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state_final\n",
       "<class 'str'>    80332\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm data types\n",
    "ufo_clean[\"state_final\"].apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5bd85f",
   "metadata": {},
   "source": [
    "### 7.11 Create initial \"country_final\" column\n",
    "\n",
    "Purpose: Combine original and shapefile-derived country values so that missing or unknown entries can be replaced with the correct geographic country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "4393377c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>country_filled</th>\n",
       "      <th>country_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>us</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unknown</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>united states of america</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gb</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>us</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>us</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country            country_filled             country_final\n",
       "0       us  United States of America                        us\n",
       "1  unknown  United States of America  united states of america\n",
       "2       gb            United Kingdom                        gb\n",
       "3       us  United States of America                        us\n",
       "4       us  United States of America                        us"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create \"country_final\" using country_filled when original is unknown\n",
    "ufo_clean[\"country_final\"] = ufo_clean.apply(\n",
    "    lambda row: row[\"country_filled\"]\n",
    "    if row[\"country\"] in [\"unknown\", None, \"\", \"nan\"]\n",
    "    else row[\"country\"], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Convert all to lowercase for consistency\n",
    "ufo_clean[\"country_final\"] = ufo_clean[\"country_final\"].str.lower()\n",
    "\n",
    "# Preview results\n",
    "ufo_clean[[\"country\", \"country_filled\", \"country_final\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de48b010",
   "metadata": {},
   "source": [
    "**Notes**: \n",
    "- All values are now lowercase and consistent. \n",
    "- Where the original country weas missing, the shapefile-assigned value is correctly used instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ff89a2",
   "metadata": {},
   "source": [
    "### 7.12 Convert full country names into 2-letter codes (dictionary method) \n",
    "\n",
    "Purpose: Convert the most common country names in the database into standard 2-letter ISO codes using a predefined dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f11b7b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to convert full country names to codes\n",
    "country_name_to_code = {\n",
    "    \"united states of america\": \"us\",\n",
    "    \"united kingdom\": \"gb\",\n",
    "    \"canada\": \"ca\",\n",
    "    \"australia\": \"au\",\n",
    "    \"new zealand\": \"nz\",\n",
    "    \"germany\": \"de\",\n",
    "    \"france\": \"fr\",\n",
    "    \"mexico\": \"mx\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "116897da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>country_filled</th>\n",
       "      <th>country_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>us</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unknown</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gb</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>us</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>us</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country            country_filled country_final\n",
       "0       us  United States of America            us\n",
       "1  unknown  United States of America            us\n",
       "2       gb            United Kingdom            gb\n",
       "3       us  United States of America            us\n",
       "4       us  United States of America            us"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply conversion\n",
    "ufo_clean[\"country_final\"] = ufo_clean[\"country_final\"].map(\n",
    "    lambda x: country_name_to_code.get(x, x)    # keep same value if no match\n",
    ")\n",
    "\n",
    "# Preview results\n",
    "ufo_clean[[\"country\", \"country_filled\", \"country_final\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f0b0b3",
   "metadata": {},
   "source": [
    "**Note**: Dictionary conversion successful standardized frequent country names; unusual or rare names remain unchanged for later cleanup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fb97bf",
   "metadata": {},
   "source": [
    "### 7.13 Validate Country Values\n",
    "\n",
    "Purpose: Review the variety of country values to identify inconsistent naming, misspellings, and non-standard geographic labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "6dbdf34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['afghanistan',\n",
       " 'aland',\n",
       " 'albania',\n",
       " 'algeria',\n",
       " 'antarctica',\n",
       " 'argentina',\n",
       " 'armenia',\n",
       " 'aruba',\n",
       " 'au',\n",
       " 'austria',\n",
       " 'azerbaijan',\n",
       " 'bahrain',\n",
       " 'bangladesh',\n",
       " 'barbados',\n",
       " 'belarus',\n",
       " 'belgium',\n",
       " 'belize',\n",
       " 'bermuda',\n",
       " 'bolivia',\n",
       " 'bosnia and herzegovina',\n",
       " 'botswana',\n",
       " 'brazil',\n",
       " 'british virgin islands',\n",
       " 'brunei',\n",
       " 'bulgaria',\n",
       " 'ca',\n",
       " 'cabo verde',\n",
       " 'cambodia',\n",
       " 'cameroon',\n",
       " 'cayman islands',\n",
       " 'chile',\n",
       " 'china',\n",
       " 'colombia',\n",
       " 'costa rica',\n",
       " 'croatia',\n",
       " 'cuba',\n",
       " 'curaçao',\n",
       " 'cyprus',\n",
       " 'czechia',\n",
       " 'de',\n",
       " 'democratic republic of the congo',\n",
       " 'denmark',\n",
       " 'dominican republic',\n",
       " 'east timor',\n",
       " 'ecuador',\n",
       " 'egypt',\n",
       " 'el salvador',\n",
       " 'estonia',\n",
       " 'eswatini',\n",
       " 'ethiopia',\n",
       " 'fiji',\n",
       " 'finland',\n",
       " 'fr',\n",
       " 'french polynesia',\n",
       " 'gb',\n",
       " 'georgia',\n",
       " 'ghana',\n",
       " 'greece',\n",
       " 'greenland',\n",
       " 'guam',\n",
       " 'guatemala',\n",
       " 'guyana',\n",
       " 'honduras',\n",
       " 'hong kong s.a.r.',\n",
       " 'hungary',\n",
       " 'iceland',\n",
       " 'india',\n",
       " 'indonesia',\n",
       " 'iran',\n",
       " 'iraq',\n",
       " 'ireland',\n",
       " 'isle of man',\n",
       " 'israel',\n",
       " 'italy',\n",
       " 'jamaica',\n",
       " 'japan',\n",
       " 'jersey',\n",
       " 'jordan',\n",
       " 'kazakhstan',\n",
       " 'kenya',\n",
       " 'kosovo',\n",
       " 'kuwait',\n",
       " 'kyrgyzstan',\n",
       " 'laos',\n",
       " 'latvia',\n",
       " 'lebanon',\n",
       " 'lesotho',\n",
       " 'libya',\n",
       " 'lithuania',\n",
       " 'luxembourg',\n",
       " 'malaysia',\n",
       " 'maldives',\n",
       " 'malta',\n",
       " 'mauritius',\n",
       " 'mongolia',\n",
       " 'morocco',\n",
       " 'mx',\n",
       " 'myanmar',\n",
       " 'namibia',\n",
       " 'nepal',\n",
       " 'netherlands',\n",
       " 'nigeria',\n",
       " 'north macedonia',\n",
       " 'northern cyprus',\n",
       " 'norway',\n",
       " 'nz',\n",
       " 'oman',\n",
       " 'pakistan',\n",
       " 'palestine',\n",
       " 'panama',\n",
       " 'paraguay',\n",
       " 'peru',\n",
       " 'philippines',\n",
       " 'poland',\n",
       " 'portugal',\n",
       " 'puerto rico',\n",
       " 'qatar',\n",
       " 'republic of serbia',\n",
       " 'romania',\n",
       " 'russia',\n",
       " 'saint helena',\n",
       " 'saint lucia',\n",
       " 'saint vincent and the grenadines',\n",
       " 'saudi arabia',\n",
       " 'senegal',\n",
       " 'singapore',\n",
       " 'slovakia',\n",
       " 'slovenia',\n",
       " 'solomon islands',\n",
       " 'south africa',\n",
       " 'south korea',\n",
       " 'spain',\n",
       " 'sri lanka',\n",
       " 'suriname',\n",
       " 'sweden',\n",
       " 'switzerland',\n",
       " 'syria',\n",
       " 'são tomé and principe',\n",
       " 'taiwan',\n",
       " 'thailand',\n",
       " 'the bahamas',\n",
       " 'tonga',\n",
       " 'trinidad and tobago',\n",
       " 'tunisia',\n",
       " 'turkey',\n",
       " 'turks and caicos islands',\n",
       " 'uganda',\n",
       " 'ukraine',\n",
       " 'united arab emirates',\n",
       " 'united states virgin islands',\n",
       " 'uruguay',\n",
       " 'us',\n",
       " 'uzbekistan',\n",
       " 'venezuela',\n",
       " 'vietnam',\n",
       " 'zambia',\n",
       " 'zimbabwe']"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(ufo_clean[\"country_final\"].dropna().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909e2837",
   "metadata": {},
   "source": [
    "**Note**: The list shows many inconsistent entries, confirming the need for systematic standardization before mapping or aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "ea04f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all country values are strings\n",
    "ufo_clean[\"country_final\"] = ufo_clean[\"country_final\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b36337",
   "metadata": {},
   "source": [
    "### 7.14 Convert Country Names to Standard 2-Letter Codes\n",
    "\n",
    "Purpose: Use pycountry to automatically convert remaining country names into valid ISO 2-letter codes after dictionary cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "c71a4495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "\n",
    "def country_to_alpha2(country):\n",
    "    if not isinstance(country, str):\n",
    "        country = str(country)\n",
    "\n",
    "    country = country.strip().lower()\n",
    "\n",
    "    try:\n",
    "        return pycountry.countries.lookup(country).alpha_2.lower()\n",
    "    except:\n",
    "        return country   # keep unchanged if no match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "fc0aa8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ae',\n",
       " 'af',\n",
       " 'al',\n",
       " 'aland',\n",
       " 'am',\n",
       " 'aq',\n",
       " 'ar',\n",
       " 'at',\n",
       " 'au',\n",
       " 'aw',\n",
       " 'az',\n",
       " 'ba',\n",
       " 'bb',\n",
       " 'bd',\n",
       " 'be',\n",
       " 'bg',\n",
       " 'bh',\n",
       " 'bm',\n",
       " 'bo',\n",
       " 'br',\n",
       " 'brunei',\n",
       " 'bw',\n",
       " 'by',\n",
       " 'bz',\n",
       " 'ca',\n",
       " 'ch',\n",
       " 'cl',\n",
       " 'cm',\n",
       " 'cn',\n",
       " 'co',\n",
       " 'cr',\n",
       " 'cu',\n",
       " 'cv',\n",
       " 'cw',\n",
       " 'cy',\n",
       " 'cz',\n",
       " 'de',\n",
       " 'democratic republic of the congo',\n",
       " 'dk',\n",
       " 'do',\n",
       " 'dz',\n",
       " 'east timor',\n",
       " 'ec',\n",
       " 'ee',\n",
       " 'eg',\n",
       " 'es',\n",
       " 'et',\n",
       " 'fi',\n",
       " 'fj',\n",
       " 'fr',\n",
       " 'gb',\n",
       " 'ge',\n",
       " 'gh',\n",
       " 'gl',\n",
       " 'gr',\n",
       " 'gt',\n",
       " 'gu',\n",
       " 'gy',\n",
       " 'hn',\n",
       " 'hong kong s.a.r.',\n",
       " 'hr',\n",
       " 'hu',\n",
       " 'id',\n",
       " 'ie',\n",
       " 'il',\n",
       " 'im',\n",
       " 'in',\n",
       " 'iq',\n",
       " 'ir',\n",
       " 'is',\n",
       " 'it',\n",
       " 'je',\n",
       " 'jm',\n",
       " 'jo',\n",
       " 'jp',\n",
       " 'ke',\n",
       " 'kg',\n",
       " 'kh',\n",
       " 'kosovo',\n",
       " 'kr',\n",
       " 'kw',\n",
       " 'ky',\n",
       " 'kz',\n",
       " 'la',\n",
       " 'lb',\n",
       " 'lc',\n",
       " 'lk',\n",
       " 'ls',\n",
       " 'lt',\n",
       " 'lu',\n",
       " 'lv',\n",
       " 'ly',\n",
       " 'ma',\n",
       " 'mk',\n",
       " 'mm',\n",
       " 'mn',\n",
       " 'mt',\n",
       " 'mu',\n",
       " 'mv',\n",
       " 'mx',\n",
       " 'my',\n",
       " 'na',\n",
       " 'nan',\n",
       " 'ng',\n",
       " 'nl',\n",
       " 'no',\n",
       " 'northern cyprus',\n",
       " 'np',\n",
       " 'nz',\n",
       " 'om',\n",
       " 'pa',\n",
       " 'palestine',\n",
       " 'pe',\n",
       " 'pf',\n",
       " 'ph',\n",
       " 'pk',\n",
       " 'pl',\n",
       " 'pr',\n",
       " 'pt',\n",
       " 'py',\n",
       " 'qa',\n",
       " 'ro',\n",
       " 'rs',\n",
       " 'russia',\n",
       " 'sa',\n",
       " 'saint helena',\n",
       " 'sb',\n",
       " 'se',\n",
       " 'sg',\n",
       " 'si',\n",
       " 'sk',\n",
       " 'sn',\n",
       " 'sr',\n",
       " 'sv',\n",
       " 'sy',\n",
       " 'sz',\n",
       " 'são tomé and principe',\n",
       " 'tc',\n",
       " 'th',\n",
       " 'the bahamas',\n",
       " 'tn',\n",
       " 'to',\n",
       " 'tt',\n",
       " 'turkey',\n",
       " 'tw',\n",
       " 'ua',\n",
       " 'ug',\n",
       " 'united states virgin islands',\n",
       " 'us',\n",
       " 'uy',\n",
       " 'uz',\n",
       " 'vc',\n",
       " 've',\n",
       " 'vg',\n",
       " 'vn',\n",
       " 'za',\n",
       " 'zm',\n",
       " 'zw']"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply conversion\n",
    "ufo_clean[\"country_final\"] = ufo_clean[\"country_final\"].apply(country_to_alpha2)\n",
    "\n",
    "# Review results\n",
    "sorted(ufo_clean[\"country_final\"].dropna().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523d94e1",
   "metadata": {},
   "source": [
    "**Note**: Some values may still convert incorrectly due to disputed territories or non-ISO regions; these will be fixed manually in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "02c9dea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country_final\n",
       "us                                  70682\n",
       "ca                                   3587\n",
       "gb                                   2352\n",
       "au                                    630\n",
       "nan                                   553\n",
       "                                    ...  \n",
       "ug                                      1\n",
       "democratic republic of the congo        1\n",
       "cw                                      1\n",
       "gu                                      1\n",
       "la                                      1\n",
       "Name: count, Length: 158, dtype: int64"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many rows per country\n",
    "ufo_clean[\"country_final\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcf407d",
   "metadata": {},
   "source": [
    "### 7.15 Fix incorrect country codes returned by pycountry\n",
    "\n",
    "Purpose: Manually correct country values that pycountry cannot resolve or returns incorrectly, ensuring accurate and consistent ISO codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "a5107fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ae',\n",
       " 'af',\n",
       " 'al',\n",
       " 'am',\n",
       " 'aq',\n",
       " 'ar',\n",
       " 'at',\n",
       " 'au',\n",
       " 'aw',\n",
       " 'ax',\n",
       " 'az',\n",
       " 'ba',\n",
       " 'bb',\n",
       " 'bd',\n",
       " 'be',\n",
       " 'bg',\n",
       " 'bh',\n",
       " 'bm',\n",
       " 'bn',\n",
       " 'bo',\n",
       " 'br',\n",
       " 'bs',\n",
       " 'bw',\n",
       " 'by',\n",
       " 'bz',\n",
       " 'ca',\n",
       " 'cd',\n",
       " 'ch',\n",
       " 'cl',\n",
       " 'cm',\n",
       " 'cn',\n",
       " 'co',\n",
       " 'cr',\n",
       " 'cu',\n",
       " 'cv',\n",
       " 'cw',\n",
       " 'cy',\n",
       " 'cz',\n",
       " 'de',\n",
       " 'dk',\n",
       " 'do',\n",
       " 'dz',\n",
       " 'ec',\n",
       " 'ee',\n",
       " 'eg',\n",
       " 'es',\n",
       " 'et',\n",
       " 'fi',\n",
       " 'fj',\n",
       " 'fr',\n",
       " 'gb',\n",
       " 'ge',\n",
       " 'gh',\n",
       " 'gl',\n",
       " 'gr',\n",
       " 'gt',\n",
       " 'gu',\n",
       " 'gy',\n",
       " 'hk',\n",
       " 'hn',\n",
       " 'hr',\n",
       " 'hu',\n",
       " 'id',\n",
       " 'ie',\n",
       " 'il',\n",
       " 'im',\n",
       " 'in',\n",
       " 'iq',\n",
       " 'ir',\n",
       " 'is',\n",
       " 'it',\n",
       " 'je',\n",
       " 'jm',\n",
       " 'jo',\n",
       " 'jp',\n",
       " 'ke',\n",
       " 'kg',\n",
       " 'kh',\n",
       " 'kr',\n",
       " 'kw',\n",
       " 'ky',\n",
       " 'kz',\n",
       " 'la',\n",
       " 'lb',\n",
       " 'lc',\n",
       " 'lk',\n",
       " 'ls',\n",
       " 'lt',\n",
       " 'lu',\n",
       " 'lv',\n",
       " 'ly',\n",
       " 'ma',\n",
       " 'mk',\n",
       " 'mm',\n",
       " 'mn',\n",
       " 'mt',\n",
       " 'mu',\n",
       " 'mv',\n",
       " 'mx',\n",
       " 'my',\n",
       " 'na',\n",
       " 'ng',\n",
       " 'nl',\n",
       " 'no',\n",
       " 'np',\n",
       " 'nz',\n",
       " 'om',\n",
       " 'pa',\n",
       " 'pe',\n",
       " 'pf',\n",
       " 'ph',\n",
       " 'pk',\n",
       " 'pl',\n",
       " 'pr',\n",
       " 'ps',\n",
       " 'pt',\n",
       " 'py',\n",
       " 'qa',\n",
       " 'ro',\n",
       " 'rs',\n",
       " 'ru',\n",
       " 'sa',\n",
       " 'sb',\n",
       " 'se',\n",
       " 'sg',\n",
       " 'sh',\n",
       " 'si',\n",
       " 'sk',\n",
       " 'sn',\n",
       " 'sr',\n",
       " 'st',\n",
       " 'sv',\n",
       " 'sy',\n",
       " 'sz',\n",
       " 'tc',\n",
       " 'th',\n",
       " 'tl',\n",
       " 'tn',\n",
       " 'to',\n",
       " 'tr',\n",
       " 'tt',\n",
       " 'tw',\n",
       " 'ua',\n",
       " 'ug',\n",
       " 'us',\n",
       " 'uy',\n",
       " 'uz',\n",
       " 'vc',\n",
       " 've',\n",
       " 'vg',\n",
       " 'vi',\n",
       " 'vn',\n",
       " 'xk',\n",
       " 'za',\n",
       " 'zm',\n",
       " 'zw']"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Manual correction dictionary for all erroneous or unrecognized values\n",
    "# Keys MUST be lowercase with no surrounding spaces - since we normalize before lookup\n",
    "country_corrections = {\n",
    "    # Aaland / Åland Islands\n",
    "    \"aland\": \"ax\",\n",
    "    \"åland\": \"ax\",\n",
    "    \"aland islands\": \"ax\",\n",
    "    \"åland islands\": \"ax\",\n",
    "\n",
    "    # Democratic Republic of Congo \n",
    "    \"democratic republic of the congo\": \"cd\",\n",
    "\n",
    "    # East Timor / Timor-Leste \n",
    "    \"east timor\": \"tl\",\n",
    "    \"timor-leste\": \"tl\",\n",
    "\n",
    "    # Palestine \n",
    "    \"palestine\": \"ps\",\n",
    "    \"state of palestine\": \"ps\",\n",
    "\n",
    "    # Kosovo (pycountry does not support officially) \n",
    "    \"kosovo\": \"xk\",\n",
    "\n",
    "    # Saint Helena \n",
    "    \"saint helena\": \"sh\",\n",
    "\n",
    "    # Bahamas \n",
    "    \"the bahamas\": \"bs\",\n",
    "    \"bahamas\": \"bs\",\n",
    "\n",
    "    # São Tomé and Príncipe (multiple variations) \n",
    "    \"são tomé and príncipe\": \"st\",\n",
    "    \"sao tomé and príncipe\": \"st\",\n",
    "    \"são tomé and principe\": \"st\",\n",
    "    \"sao tome and principe\": \"st\",\n",
    "    \"são tome and principe\": \"st\",\n",
    "    \"sao tomé and principe\": \"st\",\n",
    "\n",
    "    # Brunei\n",
    "    \"brunei\": \"bn\",\n",
    "\n",
    "    # Russia \n",
    "    \"russia\": \"ru\",\n",
    "\n",
    "    # Turkey \n",
    "    \"turkey\": \"tr\",\n",
    "\n",
    "    # Hong Kong \n",
    "    \"hong kong s.a.r.\": \"hk\",\n",
    "    \"hong kong\": \"hk\",\n",
    "\n",
    "    # United States Virgin Islands \n",
    "    \"united states virgin islands\": \"vi\",\n",
    "    \"virgin islands\": \"vi\",\n",
    "    \"usvi\": \"vi\",\n",
    "\n",
    "    # Values treated as missing \n",
    "    \"northern cyprus\": np.nan,\n",
    "    \"nan\": np.nan,\n",
    "    \"none\": np.nan,\n",
    "    \"\": np.nan,\n",
    "    \" \": np.nan\n",
    "}\n",
    "\n",
    "# Apply corrections — normalizing case + whitespace first\n",
    "def fix_country_name(x):\n",
    "    if isinstance(x, str):\n",
    "        x_clean = x.strip().lower()\n",
    "        return country_corrections.get(x_clean, x_clean)\n",
    "    return x\n",
    "\n",
    "ufo_clean[\"country_final\"] = ufo_clean[\"country_final\"].apply(fix_country_name)\n",
    "\n",
    "# Review cleaned unique list\n",
    "sorted(ufo_clean[\"country_final\"].dropna().unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3516db6e",
   "metadata": {},
   "source": [
    "**Note**: After applying corrections, remaining inconsistent or ambiguous values have been normalized or set to NaN where appropriate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f10c60a",
   "metadata": {},
   "source": [
    "### 7.16 Replace \"unknown\" and \"nan\" with NaN in country_final\n",
    "\n",
    "Purpose: Standardize all palceholder country values (\"unknown\", \"nan\", empty strings) so they are treated as true missing values (NaN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "16f4bfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country_final\n",
       "us     70682\n",
       "ca      3587\n",
       "gb      2352\n",
       "au       630\n",
       "NaN      554\n",
       "       ...  \n",
       "ug         1\n",
       "cd         1\n",
       "cw         1\n",
       "gu         1\n",
       "la         1\n",
       "Name: count, Length: 157, dtype: int64"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo_clean[\"country_final\"] = ufo_clean[\"country_final\"].replace(\n",
    "    [\"unknown\", \"nan\", \"\"],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Verify results\n",
    "ufo_clean[\"country_final\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f28fe3c",
   "metadata": {},
   "source": [
    "**Note**: The updated counts confirm that placeholder country labels were successfully removed, and only valid or missing ISO codes remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "6e4aac73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country_final\n",
       "us     70682\n",
       "ca      3587\n",
       "gb      2352\n",
       "au       630\n",
       "NaN      554\n",
       "mx       225\n",
       "in       221\n",
       "de       138\n",
       "nl       112\n",
       "za        91\n",
       "nz        88\n",
       "es        66\n",
       "fr        65\n",
       "br        63\n",
       "my        52\n",
       "jp        52\n",
       "ie        51\n",
       "be        40\n",
       "no        38\n",
       "pt        37\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo_clean[\"country_final\"].value_counts(dropna=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d7211c",
   "metadata": {},
   "source": [
    "### 7.17 Final Country Validation Checklist\n",
    "\n",
    "Purpose: Verify that rows missing \"country_final\" still contain valid latitude/longitude coordinates, ensuring they remain usable for later geographic assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "331d2cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>32.364167</td>\n",
       "      <td>-64.678611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>40.935998</td>\n",
       "      <td>-73.901708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>26.705621</td>\n",
       "      <td>-80.036430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>21.344507</td>\n",
       "      <td>-157.974891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>-33.137551</td>\n",
       "      <td>81.826172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      latitude   longitude\n",
       "18   32.364167  -64.678611\n",
       "77   40.935998  -73.901708\n",
       "174  26.705621  -80.036430\n",
       "366  21.344507 -157.974891\n",
       "515 -33.137551   81.826172"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if missing rows (NaN) have valid latitude/longitude\n",
    "ufo_clean[ufo_clean[\"country_final\"].isna()][[\"latitude\", \"longitude\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc323be",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- Most rows with missing \"country_final\" values still contain valid geographic (lat/long) coordinates.\n",
    "- Thes rows remain usable and can be accurately assigned to countries later if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "376fe70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006896380022904944"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the proportion of rows missing \"country_final\"\n",
    "len(ufo_clean[ufo_clean[\"country_final\"].isna()]) / len(ufo_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefd084e",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- Only 0.0068963...(~0.69%) of all rows are missing \"country_final\".\n",
    "- This is a small portion of the dataset and will not impact downstream geographic analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0348189",
   "metadata": {},
   "source": [
    "## 8 Build the Final Cleaned UFO Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d330c6",
   "metadata": {},
   "source": [
    "### 8.1 Select Only Final Cleaned Columns\n",
    "\n",
    "Purpose: Select only the finalized, fully cleaned columns needed for analysis and remove temporary or intermediate variables (e.g., \"state_filled\", \"country_filled\", \"geometry\", \"index_right\") to avoid redundancy and ensure clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "b9285feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'city', 'state', 'country', 'shape', 'duration (seconds)',\n",
       "       'duration (hours/min)', 'comments', 'date posted', 'latitude',\n",
       "       'longitude', 'geometry', 'country_filled', 'index_right',\n",
       "       'state_filled', 'state_final', 'country_final'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "e85793ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state_final</th>\n",
       "      <th>country_final</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-10-10 20:30:00</td>\n",
       "      <td>san marcos</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>2700</td>\n",
       "      <td>45 minutes</td>\n",
       "      <td>This event took place in early fall around 194...</td>\n",
       "      <td>2004-04-27</td>\n",
       "      <td>29.883056</td>\n",
       "      <td>-97.941111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-10-10 21:00:00</td>\n",
       "      <td>lackland afb</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>7200</td>\n",
       "      <td>1-2 hrs</td>\n",
       "      <td>1949 Lackland AFB&amp;#44 TX.  Lights racing acros...</td>\n",
       "      <td>2005-12-16</td>\n",
       "      <td>29.384210</td>\n",
       "      <td>-98.581082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1955-10-10 17:00:00</td>\n",
       "      <td>chester (uk/england)</td>\n",
       "      <td>unknown</td>\n",
       "      <td>gb</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>20 seconds</td>\n",
       "      <td>Green/Orange circular disc over Chester&amp;#44 En...</td>\n",
       "      <td>2008-01-21</td>\n",
       "      <td>53.200000</td>\n",
       "      <td>-2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956-10-10 21:00:00</td>\n",
       "      <td>edna</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>1/2 hour</td>\n",
       "      <td>My older brother and twin sister were leaving ...</td>\n",
       "      <td>2004-01-17</td>\n",
       "      <td>28.978333</td>\n",
       "      <td>-96.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960-10-10 20:00:00</td>\n",
       "      <td>kaneohe</td>\n",
       "      <td>hi</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>900</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>AS a Marine 1st Lt. flying an FJ4B fighter/att...</td>\n",
       "      <td>2004-01-22</td>\n",
       "      <td>21.418056</td>\n",
       "      <td>-157.803611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime                  city state_final country_final  \\\n",
       "0  1949-10-10 20:30:00            san marcos          tx            us   \n",
       "1  1949-10-10 21:00:00          lackland afb          tx            us   \n",
       "2  1955-10-10 17:00:00  chester (uk/england)     unknown            gb   \n",
       "3  1956-10-10 21:00:00                  edna          tx            us   \n",
       "4  1960-10-10 20:00:00               kaneohe          hi            us   \n",
       "\n",
       "      shape duration (seconds) duration (hours/min)  \\\n",
       "0  cylinder               2700           45 minutes   \n",
       "1     light               7200              1-2 hrs   \n",
       "2    circle                 20           20 seconds   \n",
       "3    circle                 20             1/2 hour   \n",
       "4     light                900           15 minutes   \n",
       "\n",
       "                                            comments date posted   latitude  \\\n",
       "0  This event took place in early fall around 194...  2004-04-27  29.883056   \n",
       "1  1949 Lackland AFB&#44 TX.  Lights racing acros...  2005-12-16  29.384210   \n",
       "2  Green/Orange circular disc over Chester&#44 En...  2008-01-21  53.200000   \n",
       "3  My older brother and twin sister were leaving ...  2004-01-17  28.978333   \n",
       "4  AS a Marine 1st Lt. flying an FJ4B fighter/att...  2004-01-22  21.418056   \n",
       "\n",
       "    longitude  \n",
       "0  -97.941111  \n",
       "1  -98.581082  \n",
       "2   -2.916667  \n",
       "3  -96.645833  \n",
       "4 -157.803611  "
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only the cleaned, final columns for analysis\n",
    "ufo_final = ufo_clean[[\n",
    "    \"datetime\",\n",
    "    \"city\",\n",
    "    \"state_final\",\n",
    "    \"country_final\",\n",
    "    \"shape\",\n",
    "    \"duration (seconds)\",\n",
    "    \"duration (hours/min)\",\n",
    "    \"comments\",\n",
    "    \"date posted\",\n",
    "    \"latitude\",\n",
    "    \"longitude\"\n",
    "]].copy()\n",
    "\n",
    "# Preview final dataset\n",
    "ufo_final.head(\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e4fc43",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- These columns form the cleaned UFO dataset used for all remaining analysis and EDA.\n",
    "- All geographic fields (\"state_final\", \"country_final\") now use standardized 2-letter codes.\n",
    "- Intermediate cleaning columns were intentionally excluded to maintain a clean, analysis-ready structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc712c5c",
   "metadata": {},
   "source": [
    "### 8.2 Sort the Final Cleaned UFO Dataset\n",
    "\n",
    "Purpose: Sort the final dataset chronologically by the datetime column to ensure all temporal analyses reflect the true historical order of sightings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "77067abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state_final</th>\n",
       "      <th>country_final</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1906-11-11 00:00:00</td>\n",
       "      <td>wien (austria)</td>\n",
       "      <td>unknown</td>\n",
       "      <td>at</td>\n",
       "      <td>other</td>\n",
       "      <td>10800</td>\n",
       "      <td>3 h</td>\n",
       "      <td>The oldest professional photo of a UFO object ...</td>\n",
       "      <td>2002-12-23</td>\n",
       "      <td>48.208174</td>\n",
       "      <td>16.373819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1910-01-02 00:00:00</td>\n",
       "      <td>kirksville (near)</td>\n",
       "      <td>mo</td>\n",
       "      <td>us</td>\n",
       "      <td>disk</td>\n",
       "      <td>120</td>\n",
       "      <td>minutes</td>\n",
       "      <td>Historical sighting (1903 - 1913) Northern Mis...</td>\n",
       "      <td>2005-09-15</td>\n",
       "      <td>40.194722</td>\n",
       "      <td>-92.583056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1910-06-01 15:00:00</td>\n",
       "      <td>wills point</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>cigar</td>\n",
       "      <td>120</td>\n",
       "      <td>2 minutes</td>\n",
       "      <td>Cigar shaped object moving from West to East</td>\n",
       "      <td>2005-04-16</td>\n",
       "      <td>32.709167</td>\n",
       "      <td>-96.008056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1916-04-05 13:00:00</td>\n",
       "      <td>france (above; from aircraft)</td>\n",
       "      <td>unknown</td>\n",
       "      <td>fr</td>\n",
       "      <td>cigar</td>\n",
       "      <td>60</td>\n",
       "      <td>about 1 min.</td>\n",
       "      <td>((NUFORC Note:  Possible hoax.  PD))  Saw 3 ci...</td>\n",
       "      <td>2004-03-09</td>\n",
       "      <td>46.227638</td>\n",
       "      <td>2.213749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1920-06-11 21:00:00</td>\n",
       "      <td>cicero</td>\n",
       "      <td>in</td>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>1 minute</td>\n",
       "      <td>((NUFORC Note:  Probable hoax.  Note date.  PD...</td>\n",
       "      <td>2009-05-12</td>\n",
       "      <td>40.123889</td>\n",
       "      <td>-86.013333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime                           city state_final  \\\n",
       "0  1906-11-11 00:00:00                 wien (austria)     unknown   \n",
       "1  1910-01-02 00:00:00              kirksville (near)          mo   \n",
       "2  1910-06-01 15:00:00                    wills point          tx   \n",
       "3  1916-04-05 13:00:00  france (above; from aircraft)     unknown   \n",
       "4  1920-06-11 21:00:00                         cicero          in   \n",
       "\n",
       "  country_final  shape duration (seconds) duration (hours/min)  \\\n",
       "0            at  other              10800                  3 h   \n",
       "1            us   disk                120              minutes   \n",
       "2            us  cigar                120            2 minutes   \n",
       "3            fr  cigar                 60         about 1 min.   \n",
       "4            us    NaN                 60             1 minute   \n",
       "\n",
       "                                            comments date posted   latitude  \\\n",
       "0  The oldest professional photo of a UFO object ...  2002-12-23  48.208174   \n",
       "1  Historical sighting (1903 - 1913) Northern Mis...  2005-09-15  40.194722   \n",
       "2       Cigar shaped object moving from West to East  2005-04-16  32.709167   \n",
       "3  ((NUFORC Note:  Possible hoax.  PD))  Saw 3 ci...  2004-03-09  46.227638   \n",
       "4  ((NUFORC Note:  Probable hoax.  Note date.  PD...  2009-05-12  40.123889   \n",
       "\n",
       "   longitude  \n",
       "0  16.373819  \n",
       "1 -92.583056  \n",
       "2 -96.008056  \n",
       "3   2.213749  \n",
       "4 -86.013333  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort final dataset by datetime (ascending, oldest -> newest)\n",
    "ufo_final = ufo_final.sort_values(by=\"datetime\").reset_index(drop=True)\n",
    "\n",
    "# Preview sorted dataset\n",
    "ufo_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee45798",
   "metadata": {},
   "source": [
    "***Notes**\n",
    "- Sorting prevents misleading trends when analyzing yearly or monthly patterns.\n",
    "- Sorting ensures the first and last sightings will match the earliest and latest datetimes in Section 8.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca07fc6",
   "metadata": {},
   "source": [
    "### 8.3 Validate the Time Range of the Dataset\n",
    "\n",
    "Purpose: Confirm the earliest and latest UFO sightings in the cleaned dataset to verify that datetime parsing and sorting were performed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "eff39010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1906-11-11 00:00:00'"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first (oldest) date in the dataset\n",
    "ufo_final[\"datetime\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "a238ec8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state_final</th>\n",
       "      <th>country_final</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-10-10 20:30:00</td>\n",
       "      <td>san marcos</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>2700</td>\n",
       "      <td>45 minutes</td>\n",
       "      <td>This event took place in early fall around 194...</td>\n",
       "      <td>2004-04-27</td>\n",
       "      <td>29.883056</td>\n",
       "      <td>-97.941111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime        city state_final country_final     shape  \\\n",
       "0  1949-10-10 20:30:00  san marcos          tx            us  cylinder   \n",
       "\n",
       "  duration (seconds) duration (hours/min)  \\\n",
       "0               2700           45 minutes   \n",
       "\n",
       "                                            comments date posted   latitude  \\\n",
       "0  This event took place in early fall around 194...  2004-04-27  29.883056   \n",
       "\n",
       "   longitude  \n",
       "0 -97.941111  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first row (earliest sighting recorded)\n",
    "ufo_final.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "aed17dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014-05-08 18:45:00'"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the most recent (latest) date in the dataset\n",
    "ufo_final[\"datetime\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "944532f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state_final</th>\n",
       "      <th>country_final</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80331</th>\n",
       "      <td>2013-09-09 23:00:00</td>\n",
       "      <td>edmond</td>\n",
       "      <td>ok</td>\n",
       "      <td>us</td>\n",
       "      <td>cigar</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>17 minutes</td>\n",
       "      <td>2 witnesses 2  miles apart&amp;#44 Red &amp;amp; White...</td>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>35.652778</td>\n",
       "      <td>-97.477778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime    city state_final country_final  shape  \\\n",
       "80331  2013-09-09 23:00:00  edmond          ok            us  cigar   \n",
       "\n",
       "      duration (seconds) duration (hours/min)  \\\n",
       "80331             1020.0           17 minutes   \n",
       "\n",
       "                                                comments date posted  \\\n",
       "80331  2 witnesses 2  miles apart&#44 Red &amp; White...  2013-09-30   \n",
       "\n",
       "        latitude  longitude  \n",
       "80331  35.652778 -97.477778  "
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first row (earliest sighting recorded)\n",
    "ufo_final.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7f0739",
   "metadata": {},
   "source": [
    "**Note**: Validation confirms no corrupted or incorrectly parsed datetime entries remain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34710b66",
   "metadata": {},
   "source": [
    "### 8.4 Export the Final Dataset to CSV\n",
    "\n",
    "Purpose: Save the cleaned UFO dataset to a CSV file for use in future notebooks, visualizations, and analysis steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "2eb0bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the cleaned, final dataset for future analysis\n",
    "ufo_final.to_csv(\"ufo_final_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a51927",
   "metadata": {},
   "source": [
    "**Note**: The exported file contains only final, standardized fields ready for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23368464",
   "metadata": {},
   "source": [
    "### 8.5 Validate Saved File Loaded Correctly\n",
    "\n",
    "Purpose: Confirm the exported dataset loads correctly and retains all expected columns and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "c34ac051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80332 entries, 0 to 80331\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   datetime              80332 non-null  object \n",
      " 1   city                  80289 non-null  object \n",
      " 2   state_final           80332 non-null  object \n",
      " 3   country_final         79778 non-null  object \n",
      " 4   shape                 72816 non-null  object \n",
      " 5   duration (seconds)    80332 non-null  object \n",
      " 6   duration (hours/min)  80332 non-null  object \n",
      " 7   comments              80316 non-null  object \n",
      " 8   date posted           80332 non-null  object \n",
      " 9   latitude              80332 non-null  float64\n",
      " 10  longitude             80332 non-null  float64\n",
      "dtypes: float64(2), object(9)\n",
      "memory usage: 6.7+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nlnz8\\AppData\\Local\\Temp\\ipykernel_124244\\238246712.py:1: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test = pd.read_csv(\"ufo_final_cleaned.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state_final</th>\n",
       "      <th>country_final</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-10-10 20:30:00</td>\n",
       "      <td>san marcos</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>2700</td>\n",
       "      <td>45 minutes</td>\n",
       "      <td>This event took place in early fall around 194...</td>\n",
       "      <td>2004-04-27</td>\n",
       "      <td>29.883056</td>\n",
       "      <td>-97.941111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-10-10 21:00:00</td>\n",
       "      <td>lackland afb</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>7200</td>\n",
       "      <td>1-2 hrs</td>\n",
       "      <td>1949 Lackland AFB&amp;#44 TX.  Lights racing acros...</td>\n",
       "      <td>2005-12-16</td>\n",
       "      <td>29.384210</td>\n",
       "      <td>-98.581082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1955-10-10 17:00:00</td>\n",
       "      <td>chester (uk/england)</td>\n",
       "      <td>unknown</td>\n",
       "      <td>gb</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>20 seconds</td>\n",
       "      <td>Green/Orange circular disc over Chester&amp;#44 En...</td>\n",
       "      <td>2008-01-21</td>\n",
       "      <td>53.200000</td>\n",
       "      <td>-2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956-10-10 21:00:00</td>\n",
       "      <td>edna</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>1/2 hour</td>\n",
       "      <td>My older brother and twin sister were leaving ...</td>\n",
       "      <td>2004-01-17</td>\n",
       "      <td>28.978333</td>\n",
       "      <td>-96.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960-10-10 20:00:00</td>\n",
       "      <td>kaneohe</td>\n",
       "      <td>hi</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>900</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>AS a Marine 1st Lt. flying an FJ4B fighter/att...</td>\n",
       "      <td>2004-01-22</td>\n",
       "      <td>21.418056</td>\n",
       "      <td>-157.803611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime                  city state_final country_final  \\\n",
       "0  1949-10-10 20:30:00            san marcos          tx            us   \n",
       "1  1949-10-10 21:00:00          lackland afb          tx            us   \n",
       "2  1955-10-10 17:00:00  chester (uk/england)     unknown            gb   \n",
       "3  1956-10-10 21:00:00                  edna          tx            us   \n",
       "4  1960-10-10 20:00:00               kaneohe          hi            us   \n",
       "\n",
       "      shape duration (seconds) duration (hours/min)  \\\n",
       "0  cylinder               2700           45 minutes   \n",
       "1     light               7200              1-2 hrs   \n",
       "2    circle                 20           20 seconds   \n",
       "3    circle                 20             1/2 hour   \n",
       "4     light                900           15 minutes   \n",
       "\n",
       "                                            comments date posted   latitude  \\\n",
       "0  This event took place in early fall around 194...  2004-04-27  29.883056   \n",
       "1  1949 Lackland AFB&#44 TX.  Lights racing acros...  2005-12-16  29.384210   \n",
       "2  Green/Orange circular disc over Chester&#44 En...  2008-01-21  53.200000   \n",
       "3  My older brother and twin sister were leaving ...  2004-01-17  28.978333   \n",
       "4  AS a Marine 1st Lt. flying an FJ4B fighter/att...  2004-01-22  21.418056   \n",
       "\n",
       "    longitude  \n",
       "0  -97.941111  \n",
       "1  -98.581082  \n",
       "2   -2.916667  \n",
       "3  -96.645833  \n",
       "4 -157.803611  "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"ufo_final_cleaned.csv\")\n",
    "\n",
    "test.info()\n",
    "test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
